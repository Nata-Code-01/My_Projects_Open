Ссылка на коллаб: https://colab.research.google.com/drive/1y6f-Ux5al1JUeC4sxksLirh59-lUOp8e?usp=drive_link

#Задание 1
'''
Задана модель нейронной сети следующей структуры:

input_dim = 3 - размерность входных данных
Dense(3) - первый полносвязный слой с тремя нейронами
Dense(1) - второй полносвязный слой с одним нейроном.
Создайте модель заданной структуры, для этого:

импортируйте библиотеку для создания модели
импортируйте библиотеку для создания необходимых слоев
создайте модель полносвязной сети
добавьте заданные слои в модель.
Выведите структуру модели с помощью функции .summary().

Выведите веса модели с помощью функции .get_weights().
'''

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model1 = Sequential()                                                           # Создание последовательной модели.
model1.add(Dense(3, input_dim = 3, activation = 'relu'))                        # Добавление полносвязного слоя на 3 нейрона с relu-активацией.
model1.add(Dense(1, activation = 'sigmoid'))                                    # Добавление полносвязного слоя с 1 нейроном с sigmoid-активацией.

print(model1.summary())                                                         # Вывод структуры модели.
print(model1.get_weights())                                                     # Вывод весов модели.

#Задание 2. Создайте такую же нейронную сеть, как в первом задании, отключив нейрон смещения - параметр use_bias=False, используемый при создании полносвязного слоя. 
#Выведите структуру модели и веса. Посмотрите, что изменилось.

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model2 = Sequential()                                                           # Создание последовательной модели.
model2.add(Dense(3, input_dim = 3, activation = 'relu', use_bias = False))      # Добавление полносвязного слоя на 3 нейрона с relu-активацией без нейрона смещения.
model2.add(Dense(1, activation = 'sigmoid', use_bias = False))                  # Добавление полносвязного слоя с 1 нейроном с sigmoid-активацией без нейрона смещения.

print(model2.summary())                                                         # Вывод структуры модели.
print(model2.get_weights())                                                     # Вывод весов модели.

#Можно заметить, что изменилось количество параметров модели. Это и было ожидаемо, ведь мы отключили нейрон смещения, который также обладал параметрами в предыдущей модели.

#Задание 3
'''
Создайте набор числовых данных размерностью (1, 3) для обучения нейронной сети.
Импортируйте библиотеку для работы с массивами
задайте три числовых значения
с помощью функции .array() создайте массив из трёх заданных значений
с помощью функции .expand_dims() получите требуемую размерность входных данных - (1, 3)
выведите размерность получившегося массива с помощью метода .shape
'''

import numpy as np                                                              # Работа с массивами.

a, b, c = 8.0, 9.0, 2.0                                                         # Задаём три числовых значения.
numbers = np.array([a, b, c])                                                   # Создаём массив из этих значений.
numbers_new = np.expand_dims(numbers, axis=0)                                   # Получим требуемую размерность (1, 3).

print(numbers_new.shape)                                                        # Вывод размерности массива.

#Задание 4. С помощью функции .predict() получите значение выхода сети, передав на вход вектор из трёх элементов, полученный в предыдущем задании.

result = model2.predict(numbers_new)                                            # Получим значение выхода модели для numbers_new.
print(result)    

#Задание 5. Самостоятельно посчитайте выход сети, воспользовавшись массивом, полученным в задании 2, используя правила матричного перемножения.
#weights=model.get_weights()

W = model2.get_weights()                                                        # Получаем веса модели.
w1, w2 = W[0], W[1]                                                             # Извлекаем веса скрытого и выходного слоя.

res = np.maximum(0, np.dot(numbers_new, w1))                                    # Получаем выход скрытого слоя (полученную сумму произведений прогоняем через 'Relu').

result = 1 / (1 + np.exp(-np.dot(res, w2)))                                     # Получаем выход последнего слоя (полученную сумму произведений прогоняем через 'Sigmoid').

print(result)                                                                   # Отображение результата.
#Как видим, результат совпал с результатами предыдущего пункта.

#Задание 6. Создайте нейронную сеть следующей структуры:
'''
размер входных данных: 8
полносвязный слой из 100 нейронов
полносвязный слой из 10 нейронов
полносвязный слой из 2 нейронов.
Выведите summary модели.
'''

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model3 = Sequential()                                                           # Создание последовательной модели.
model3.add(Dense(100, input_dim = 8, activation = 'relu'))                      # Добавление полносвязного слоя на 100 нейронов с relu-активацией.
model3.add(Dense(10, activation = 'sigmoid'))                                   # Добавление полносвязного слоя на 10 нейронов с sigmoid-активацией.
model3.add(Dense(2, activation = 'softmax'))                                    # Добавление полносвязного слоя с 2 нейронами с softmax-активацией.

print(model3.summary())                                                         # Вывод структуры модели.

#Задание 7. Создайте нейронную сеть с такой же структурой, как в задаче 6, но без нейрона смещения во всех слоях.

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model4 = Sequential()                                                           # Создание последовательной модели.
model4.add(Dense(100, input_dim = 8, activation = 'relu', use_bias = False))    # Добавление полносвязного слоя на 100 нейронов с relu-активацией без нейрона смещения.
model4.add(Dense(10, activation = 'sigmoid', use_bias = False))                 # Добавление полносвязного слоя на 10 нейронов с sigmoid-активацией без нейрона смещения.
model4.add(Dense(2, activation = 'softmax', use_bias = False))                  # Добавление полносвязного слоя с 2 нейронами с softmax-активацией без нейрона смещения.

print(model4.summary())                                                         # Вывод структуры модели.

#Задание 8. Выведите веса модели из задачи 7 с помощью функции .get_weights().

print(model4.get_weights())                                                     # Вывод весов модели.

#Задание 9. Задайте значения весов для модели следующей структуры:
'''
размерность входных данных равна 2
количество нейронов на первом скрытом слое равно 2
количество нейронов на втором скрытом слое равно 2
количество нейронов на выходном слое равно 1
нейрон смещения отключен на всех слоях.
'''

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.
import numpy as np                                                              # Работа с массивами.

model5 = Sequential()                                                           # Создание последовательной модели.
model5.add(Dense(2, input_dim = 2, use_bias = False))                           # Добавление полносвязного слоя на 2 нейрона без нейрона смещения.
model5.add(Dense(2, use_bias = False))                                          # Добавление полносвязного слоя на 2 нейрона без нейрона смещения.
model5.add(Dense(1, use_bias = False))                                          # Добавление полносвязного слоя с 1 нейроном без нейрона смещения.

model5.summary()                                                                # Вывод структуры модели.

w1, w2, w3, w4, w5, w6, w7, w8, w9, w10 = -0.1, 0.2, -0.5, 0.8, 0.3, 0.4, -0.3, 0.5, 0.9, 0.1            # Задаём значения весов.

new_weights = [np.array([[w1, w2], [w3, w4]]), np.array([[w5, w6], [w7, w8]]), np.array([[w9], [w10]])]  # Формируем список весов.

model5.set_weights(new_weights)                                                 # Меняем веса модели.

print(model5.get_weights())                                                     # Вывод весов модели.

#Задание 10. Создайте модель для реализации структуры из задачи 9.

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model6 = Sequential()                                                           # Создание последовательной модели.
model6.add(Dense(2, input_dim = 2, use_bias = False))                           # Добавление полносвязного слоя на 2 нейрона без нейрона смещения.
model6.add(Dense(2, use_bias = False))                                          # Добавление полносвязного слоя на 2 нейрона без нейрона смещения.
model6.add(Dense(1, use_bias = False))                                          # Добавление полносвязного слоя с 1 нейроном без нейрона смещения.

model6.summary()                                                                # Вывод структуры модели.

#Задание 11. Создайте входной вектор из числовых значений, который можно использовать для формирования модели из задачи 10.
#Пример создания входного вектора размерностью (1, 3): x1 = 5 x2 = 1 x3 = 6 x_train = np.expand_dims(np.array([x1, x2, x3]), 0)

import numpy as np                                                              # Работа с массивами.

x1 = 0.8                                                                        # Первый элемент вектора.
x2 = -0.1                                                                       # Второй элемент вектора.

x_train = np.expand_dims(np.array([x1, x2]), 0)                                 # Формируем вектор.

print(x_train.shape)                                                            # Выводим размерность вектора на экран.
#Так как размерность входных данных рассматриваемой модели равна 2, то в нашем векторе будет 2 элемента x1 и x2.

#Задание 12. Задайте созданные в задаче 9 веса в модель из задания 10 с помощью функции .set_weights().

model6.set_weights(new_weights)                                                 # Меняем веса модели №6 (из задания 10).

print(model6.get_weights())                                                     # Вывод весов модели №6 (из задания 10).

#Задание 13. Получите значения выхода сети с помощью функции .predict(), воспользовавшись вектором из задачи 11.

print(model6.predict(x_train))                                                  # Получаем значение выхода сети модели №6.

#Задание 14. Создайте нейронную сеть, содержащую три слоя, для классификации цифр от 0 до 5 включительно, с размерностью входных данных 256. Отобразите структуру модели.

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model7 = Sequential()                                                           # Создание последовательной модели.
model7.add(Dense(128, input_dim = 256, activation = 'relu'))                    # Добавление полносвязного скрытого слоя на 128 нейронов с функцией активации 'relu'.
model7.add(Dense(64, activation = 'relu'))                                      # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model7.add(Dense(6, activation = 'softmax'))                                    # Добавление полносвязного слоя на 128 нейронов с функцией активации 'softmax'.

model7.summary()                                                                # Вывод структуры модели.
#В скрытых слоях используем функцию активации 'relu', а на выходном слое 'softmax', т.к. она хорошо подходит для классификации элементов.


#Задание 15. Создайте нейронную сеть для классификации 5-и видов диких животных по фотографии 25х25. Постройте архитектуру нейронной сети, содержащую шесть слоев.

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense, Flatten                              # Подключение класса Dense - полносвязный слой, и Flatten - преобразование массивов.

model8 = Sequential()                                                           # Создание последовательной модели.
model8.add(Flatten(input_shape = (25, 25, 3)))                                  # Преобразование изображения в вектор.
model8.add(Dense(512, activation = 'relu'))                                     # Добавление полносвязного скрытого слоя на 512 нейронов с функцией активации 'relu'.
model8.add(Dense(256, activation = 'relu'))                                     # Добавление полносвязного скрытого слоя на 256 нейроов с функцией активации 'relu'.
model8.add(Dense(128, activation = 'relu'))                                     # Добавление полносвязного скрытого слоя на 128 нейронов с функцией активации 'relu'.
model8.add(Dense(64, activation = 'relu'))                                      # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model8.add(Dense(5, activation = 'softmax'))                                    # Добавление полносвязного слоя на 5 нейронов с функцией активации 'softmax'.

model8.summary()                                                                # Вывод структуры модели.
#Здесь аналогично в скрытых слоях используем функцию активации relu, а на выходном слое softmax, т.к. она хорошо подходит для классификации элементов. 
#Нейронов в выходном слое 5, т.к. по условию классификация 5-ти видов животных.

#Задание 16. Создайте нейронную сеть, использующую температуру тела и давление для отличия больного человека от здорового. 
#Постройте архитектуру нейронной сети, содержащую четыре слоя, на выходном слое используйте функцию активации linear. И предусмотрите нормализацию входных данных

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense, BatchNormalization                   # Подключение класса Dense - полносвязный слой, и BatchNormalization - нормализация.

model9 = Sequential()                                                           # Создание последовательной модели.
model9.add(BatchNormalization(input_shape = (2,)))                              # Нормализация входных данных.
model9.add(Dense(64, activation = 'relu'))                                      # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model9.add(Dense(32, activation = 'relu'))                                      # Добавление полносвязного скрытого слоя на 32 нейрона с функцией активации 'relu'.
model9.add(Dense(16, activation = 'relu'))                                      # Добавление полносвязного скрытого слоя на 16 нейронов с функцией активации 'relu'.
model9.add(Dense(1, activation = 'linear'))                                     # Добавление полносвязного выходного слоя на 1 нейрон с функцией активации 'linear'.

model9.summary()                                                                # Вывод структуры модели.

#Здесь в выходном слое используем активационную функцию linear, по условию задачи. 
#Нейронов в выходном слое 1, т.к. нейросеть должна ответить на вопрос, болен человек или нет. 
#Входные данные нормализуются с помощью BatchNormalization. В остальных скрытых слоях используем активационные функции relu.

#Задание 17
Создайте нейронную сеть, отличающую мак от розы по изображению 12 на 12 пикселей. Постройте архитектуру нейронной сети, содержащую два слоя, на выходном слое используйте функцию активации sigmoid.

#from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense, Flatten                              # Подключение класса Dense - полносвязный слой, и Flatten - преобразование массивов.

model10 = Sequential()                                                          # Создание последовательной модели.
model10.add(Flatten(input_shape = (12, 12, 3)))                                 # Преобразование изображения в вектор.
model10.add(Dense(64, activation = 'relu'))                                     # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model10.add(Dense(1, activation = 'sigmoid'))                                   # Добавление полносвязного выходного слоя на 1 нейрон с функцией активации 'linear'.

model10.summary()                                                               # Вывод структуры модели.

#Здесь в выходном слое используем активационную функцию sigmoid, т.к. того требует условие задачи. 
#Нейронов в выходном слое 1, т.к. необходимо отличить из двух объектов один. Вводные данные, т.е. картинки, преобразовываем в вектор.

#Задание 18
Создайте нейронную сеть для классификации пресмыкающихся по трем категориям. Известно, что каждая категория характеризуется 8-ю числовыми признаками. 
#Постройте архитектуру нейронной сети, содержащую три слоя с различными активационными функциями для решения поставленной задачи.

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model11 = Sequential()                                                          # Создание последовательной модели.
model11.add(Dense(64, input_dim = 8, activation = 'relu'))                      # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model11.add(Dense(32, activation = 'sigmoid'))                                  # Добавление полносвязного скрытого слоя на 32 нейрона с функцией активации 'sigmoid'.
model11.add(Dense(16, activation = 'tanh'))                                     # Добавление полносвязного скрытого слоя на 16 нейронов с функцией активации 'tanh'.
model11.add(Dense(3, activation = 'softmax'))                                   # Добавление полносвязного выходного слоя на 3 нейрона с функцией активации 'softmax'.

model11.summary()                                                               # Вывод структуры модели.

#Здесь, аналогично другим примерам, в выходном слое используем активационную функцию softmax, т.к. по условию происходит классификация. 
#Нейронов в выходном слое 3, т.к. классификация по 3-м категорям. Размерность вводных данных 8, т.к. объекты характеризуются 8-ю числовыми признаками. 
#В остальных скрытых слоях используем различные активационные функции, как это требовалось по условию.

#Задание 19. Создайте систему компьютерного зрения, которая будет определять тип геометрической фигуры. 
#Используя подготовленную базу и шаблон ноутбука проведите серию экспериментов по перебору гиперпараметров нейронной сети, распознающей три категории изображений (треугольник, круг, квадрат).
'''
Поменяйте количество нейронов в сети, используя следующие значения:
один слой 10 нейронов
один слой 100 нейронов
один слой 5000 нейронов.
Поменяйте активационную функцию в скрытых слоях с relu на linear.
Поменяйте размеры batch_size:
10
100
1000
Выведите на экран получившиеся точности.
'''

# Подключение класса для создания нейронной сети прямого распространения
from tensorflow.keras.models import Sequential
# Подключение класса для создания полносвязного слоя
from tensorflow.keras.layers import Dense
# Подключение оптимизатора
from tensorflow.keras.optimizers import Adam
# Подключение утилит для to_categorical
from tensorflow.keras import utils
# Подключение библиотеки для загрузки изображений
from tensorflow.keras.preprocessing import image
# Подключение библиотеки для работы с массивами
import numpy as np
# Подключение библиотек для отрисовки изображений
import matplotlib.pyplot as plt
# Подключение модуля для работы с файлами
import os
# Вывод изображения в ноутбуке, а не в консоли или файле
%matplotlib inline

# Загрузка датасета из облака
import gdown
gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l3/hw_light.zip', None, quiet=True)

# Распаковываем архив hw_light.zip в папку hw_light
!unzip -q hw_light.zip

# Путь к директории с базой
base_dir = '/content/hw_light'
# Создание пустого списка для загрузки изображений обучающей выборки
x_train = []
# Создание списка для меток классов
y_train = []
# Задание высоты и ширины загружаемых изображений
img_height = 20
img_width = 20
# Перебор папок в директории базы
for patch in os.listdir(base_dir):
    # Перебор файлов в папках
    for img in os.listdir(base_dir + '/' + patch):
        # Добавление в список изображений текущей картинки
        x_train.append(image.img_to_array(image.load_img(base_dir + '/' + patch + '/' + img,
                                                    target_size=(img_height, img_width),
                                                    color_mode='grayscale')))
        # Добавление в массив меток, соответствующих классам
        if patch == '0':
            y_train.append(0)
        elif patch == '3':
            y_train.append(1)
        else:
            y_train.append(2)

# Преобразование в numpy-массив загруженных изображений и меток классов
x_train = np.array(x_train)
y_train = np.array(y_train)
# Вывод размерностей
print('Размер массива x_train', x_train.shape)
print('Размер массива y_train', y_train.shape)

from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model11 = Sequential()                                                          # Создание последовательной модели.
model11.add(Dense(64, input_dim = 8, activation = 'relu'))                      # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model11.add(Dense(32, activation = 'sigmoid'))                                  # Добавление полносвязного скрытого слоя на 32 нейрона с функцией активации 'sigmoid'.
model11.add(Dense(16, activation = 'tanh'))                                     # Добавление полносвязного скрытого слоя на 16 нейронов с функцией активации 'tanh'.
model11.add(Dense(3, activation = 'softmax'))                                   # Добавление полносвязного выходного слоя на 3 нейрона с функцией активации 'softmax'.

model11.summary()                                                               # Вывод структуры модели.

from tensorflow.keras.layers import Flatten
from sklearn.model_selection import train_test_split

y_train = utils.to_categorical(y_train, 3)
x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)

def func(n, b):
    model12 = Sequential()                                                      # Создание последовательной модели.
    model12.add(Flatten(input_shape = (20, 20, 1)))
    model12.add(Dense(n, activation = 'relu'))                                  # Добавление полносвязного скрытого слоя на n нейронов с функцией активации 'relu'.
                                                                                # Можно заменить на linear и посмотреть, что получится.
    model12.add(Dense(3, activation = 'softmax'))                               # Добавление полносвязного выходного слоя на 3 нейрона с функцией активации 'softmax'.
    model12.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy']) # Задание  параметров обучения модели.
    history = model12.fit(x_train, y_train, epochs = 5, batch_size = b, validation_data = (x_test, y_test), verbose = 1) # Обучение модели.
    return history.history['accuracy'][-1]                                      # Возвращаем точность.
acc = {}                                                                        # Создадим словарь для хранения результатов.
N = [10, 100, 5000]                                                             # Список количества нейронов для разных случаев.
B = [10, 100, 1000]                                                             # Список размера разбиений тестовой выборки для разных случаев.
for i in N:
    for j in B:
        accuracy = func(i, j)
        acc[f'нейронов - {i} и batch_size = {j}'] = accuracy
for i, j in acc.items():
    print(f'Точность для {i}: {j}')

#Таким образом, можно заметить, что если поменять функцию активации в скрытом слое на linear, точность заметно упадёт. 
#Это связано с тей, что обучать модели с линейной функцией в скрытых слоях неэффективно. 
#Кроме того, чем меньше разбиение на batch_size, тем точность выше, модель учится лучше. Количество нейронов влияет, но не сильно.

#Задание 20. Самостоятельно напишите нейронную сеть, которая может стать составной частью системы бота для игры в "Крестики-нолики". 
#Используя подготовленную базу изображений, создайте и обучите нейронную сеть, распознающую две категории изображений: крестики и нолики. Добейтесь точности распознавания более 95% (accuracy)

# Подключение класса для создания нейронной сети прямого распространения
from tensorflow.keras.models import Sequential
# Подключение класса для создания полносвязного слоя
from tensorflow.keras.layers import Dense
# Подключение оптимизатора
from tensorflow.keras.optimizers import Adam
# Подключение утилит для to_categorical
from tensorflow.keras import utils
# Подключение библиотеки для загрузки изображений
from tensorflow.keras.preprocessing import image
# Подключение библиотеки для работы с массивами
import numpy as np
# Подключение модуля для работы с файлами
import os
# Подключение библиотек для отрисовки изображений
import matplotlib.pyplot as plt
from PIL import Image
# Вывод изображения в ноутбуке, а не в консоли или файле
%matplotlib inline

# Загрузка датасета из облака
import gdown
gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l3/hw_pro.zip', None, quiet=True)

# Распаковываем архив hw_light.zip в папку hw_light
!unzip -q hw_pro.zip

# Путь к директории с базой
base_dir = '/content/hw_pro'
# Создание пустого списка для загрузки изображений обучающей выборки
x_train = []
# Создание списка для меток классов
y_train = []
# Задание высоты и ширины загружаемых изображений
img_height = 20
img_width = 20
# Перебор папок в директории базы
for patch in os.listdir(base_dir):
    # Перебор файлов в папках
    for img in os.listdir(base_dir + '/' + patch):
        # Добавление в список изображений текущей картинки
        x_train.append(image.img_to_array(image.load_img(base_dir + '/' + patch + '/' + img,
                                                         target_size=(img_height, img_width),
                                                         color_mode='grayscale')))
        # Добавление в массив меток, соответствующих классам
        if patch == '0':
            y_train.append(0)
        else:
            y_train.append(1)
# Преобразование в numpy-массив загруженных изображений и меток классов
x_train = np.array(x_train)
y_train = np.array(y_train)
# Вывод размерностей
print('Размер массива x_train', x_train.shape)
print('Размер массива y_train', y_train.shape)

from tensorflow.keras.layers import Flatten

#Нормализация входных данных.
y_train = utils.to_categorical(y_train, 2)                                      # Преобразуем в OHE.
x_train = x_train / 255.0

model13 = Sequential()                                                          # Создание последовательной модели.
model13.add(Flatten(input_shape=(20, 20, 1)))
model13.add(Dense(64, activation='relu'))                                       # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model13.add(Dense(32, activation='relu'))                                       # Добавление полносвязного скрытого слоя на 32 нейронов с функцией активации 'relu'.
model13.add(Dense(2, activation='softmax'))                                     # Добавление полносвязного выходного слоя на 2 нейрона с функцией активации 'softmax'.

model13.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy']) # Задание парметров обучения.
h = model13.fit(x_train, y_train, epochs = 15, batch_size = 15, validation_split = 0.2, verbose = 1) # Обучение модели.

print(f"Точность модели: {h.history['accuracy'][-1]}")

#Задание 21. Распознайте рукописную цифру, написанную на листе от руки. Последовательность шагов следующая:
'''
На бумаге рисуем произвольную цифру (желательно нарисовать цифру размером не более 5 * 5 мм и без наклона. В занятии нейронка обучалась на цифрах американских студентов. Эти цифры были написаны на тетрадных листах в клетку и имели схожий размер).
Фотографируем. Загружаем фото в Collaboratory.
С помощью функции image.load_img(path, target_size=(28, 28), color_mode = ‘grayscale’) загружаем картинку в переменную.
С помощью функции image.img_to_array(img) преобразуем изображение в numpy-массив.
Выполняем инверсию цветов, нормирование и решейп массива.
Выполняем распознавание собственной рукописной цифры.
Примечание: точность распознавания рукописных цифр может быть достаточно низкой, т.к. рукописные цифры после преобразований хоть и похожи на содержащиеся в базе, но могут отличаться по конфигурации, толщине линий и т.д.

Для выполнения этого задания нам понадобится код, который был написан на паре для распознавания цифр MNIST.
'''

from tensorflow.keras.datasets import mnist     # Библиотека с базой рукописных цифр
from tensorflow.keras.models import Sequential  # Подключение класса создания модели Sequential
from tensorflow.keras.layers import Dense       # Подключение класса Dense - полносвязный слой
from tensorflow.keras import utils              # Утилиты для подготовки данных
import numpy as np                              # Работа с массивами
import matplotlib.pyplot as plt                 # Отрисовка изображений

# Отрисовка изображений в ячейках ноутбука
%matplotlib inline

# Загрузка из облака данных Mnist
(x_train_org, y_train_org), (x_test_org, y_test_org) = mnist.load_data()

# Изменение формы входных картинок с 28х28 на 784
# первая ось остается без изменения, остальные складываются в вектор
x_train = x_train_org.reshape(x_train_org.shape[0], -1)
x_test = x_test_org.reshape(x_test_org.shape[0], -1)

# Нормализация входных картинок
# Преобразование x_train в тип float32 (числа с плавающей точкой) и нормализация
x_train = x_train.astype('float32') / 255.

# Преобразование x_test в тип float32 (числа с плавающей точкой) и нормализация
x_test = x_test.astype('float32') / 255.

# Задание константы количества распознаваемых классов

CLASS_COUNT = 10
# Преобразование ответов в формат one_hot_encoding
y_train = utils.to_categorical(y_train_org, CLASS_COUNT)
y_test = utils.to_categorical(y_test_org, CLASS_COUNT)

# Создание последовательной модели
model = Sequential()
# Добавление полносвязного слоя на 800 нейронов с relu-активацией
model.add(Dense(800, input_dim=784, activation='relu'))
# Добавление полносвязного слоя на 400 нейронов с relu-активацией
model.add(Dense(400, activation='relu'))
# Добавление полносвязного слоя с количеством нейронов по числу классов с softmax-активацией
model.add(Dense(CLASS_COUNT, activation='softmax'))
# Компиляция модели
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Вывод структуры модели
print(model.summary())

model.fit(x_train,        # обучающая выборка, входные данные
          y_train,        # обучающая выборка, выходные данные
          batch_size=128, # кол-во примеров, которое обрабатывает нейронка перед одним изменением весов
          epochs=15,      # количество эпох, когда нейронка обучается на всех примерах выборки
          verbose=1)      # 0 - не визуализировать ход обучения, 1 - визуализировать

img = '8.jpg'                                                                   # Наше фото.
img_p = image.load_img(img, target_size=(28, 28), color_mode='grayscale')       # Загружаем картинку в переменную.
x_test = image.img_to_array(img_p)                                              # Преобразуем в массив.

x_test = 255 - x_test                                                           # Инверсия цветов.
x_test = x_test.astype('float32') / 255.                                        # Нормализация.
x_test = x_test.reshape(1, 784)                                                 # Решейп массива.

res = model.predict(x_test)                                                     # Отправляем цифру в модель.

print(f"Распознана цифра: {np.argmax(res)}")                                    # выводим результат.
#Четвёртое домашнее задание.
Задание 1
Задана модель нейронной сети следующей структуры:

input_dim = 3 - размерность входных данных
Dense(3) - первый полносвязный слой с тремя нейронами
Dense(1) - второй полносвязный слой с одним нейроном.
Создайте модель заданной структуры, для этого:

импортируйте библиотеку для создания модели
импортируйте библиотеку для создания необходимых слоев
создайте модель полносвязной сети
добавьте заданные слои в модель.
Выведите структуру модели с помощью функции .summary().

Выведите веса модели с помощью функции .get_weights().


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model1 = Sequential()                                                           # Создание последовательной модели.
model1.add(Dense(3, input_dim = 3, activation = 'relu'))                        # Добавление полносвязного слоя на 3 нейрона с relu-активацией.
model1.add(Dense(1, activation = 'sigmoid'))                                    # Добавление полносвязного слоя с 1 нейроном с sigmoid-активацией.

print(model1.summary())                                                         # Вывод структуры модели.
print(model1.get_weights())                                                     # Вывод весов модели.

Задание 2
Создайте такую же нейронную сеть, как в первом задании, отключив нейрон смещения - параметр use_bias=False, используемый при создании полносвязного слоя. Выведите структуру модели и веса. Посмотрите, что изменилось.


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model2 = Sequential()                                                           # Создание последовательной модели.
model2.add(Dense(3, input_dim = 3, activation = 'relu', use_bias = False))      # Добавление полносвязного слоя на 3 нейрона с relu-активацией без нейрона смещения.
model2.add(Dense(1, activation = 'sigmoid', use_bias = False))                  # Добавление полносвязного слоя с 1 нейроном с sigmoid-активацией без нейрона смещения.

print(model2.summary())                                                         # Вывод структуры модели.
print(model2.get_weights())                                                     # Вывод весов модели.

Можно заметить, что изменилось количество параметров модели. Это и было ожидаемо, ведь мы отключили нейрон смещения, который также обладал параметрами в предыдущей модели.

Задание 3
Создайте набор числовых данных размерностью (1, 3) для обучения нейронной сети.

импортируйте библиотеку для работы с массивами
задайте три числовых значения
с помощью функции .array() создайте массив из трёх заданных значений
с помощью функции .expand_dims() получите требуемую размерность входных данных - (1, 3)
выведите размерность получившегося массива с помощью метода .shape

[ ]
import numpy as np                                                              # Работа с массивами.

a, b, c = 8.0, 9.0, 2.0                                                         # Задаём три числовых значения.
numbers = np.array([a, b, c])                                                   # Создаём массив из этих значений.
numbers_new = np.expand_dims(numbers, axis=0)                                   # Получим требуемую размерность (1, 3).

print(numbers_new.shape)                                                        # Вывод размерности массива.
(1, 3)
Задание 4
С помощью функции .predict() получите значение выхода сети, передав на вход вектор из трёх элементов, полученный в предыдущем задании.


[ ]
result = model2.predict(numbers_new)                                            # Получим значение выхода модели для numbers_new.
print(result)                                                                   # Отображение результата.
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 223ms/step
[[0.00286615]]
Задание 5
Самостоятельно посчитайте выход сети, воспользовавшись массивом, полученным в задании 2, используя правила матричного перемножения.

weights=model.get_weights()

image.png


[ ]
W = model2.get_weights()                                                        # Получаем веса модели.
w1, w2 = W[0], W[1]                                                             # Извлекаем веса скрытого и выходного слоя.

res = np.maximum(0, np.dot(numbers_new, w1))                                    # Получаем выход скрытого слоя (полученную сумму произведений прогоняем через 'Relu').

result = 1 / (1 + np.exp(-np.dot(res, w2)))                                     # Получаем выход последнего слоя (полученную сумму произведений прогоняем через 'Sigmoid').

print(result)                                                                   # Отображение результата.
[[0.00286615]]
Как видим, результат совпал с результатами предыдущего пункта.

Задание 6
Создайте нейронную сеть следующей структуры:

размер входных данных: 8
полносвязный слой из 100 нейронов
полносвязный слой из 10 нейронов
полносвязный слой из 2 нейронов.
Выведите summary модели.


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model3 = Sequential()                                                           # Создание последовательной модели.
model3.add(Dense(100, input_dim = 8, activation = 'relu'))                      # Добавление полносвязного слоя на 100 нейронов с relu-активацией.
model3.add(Dense(10, activation = 'sigmoid'))                                   # Добавление полносвязного слоя на 10 нейронов с sigmoid-активацией.
model3.add(Dense(2, activation = 'softmax'))                                    # Добавление полносвязного слоя с 2 нейронами с softmax-активацией.

print(model3.summary())                                                         # Вывод структуры модели.

Задание 7
Создайте нейронную сеть с такой же структурой, как в задаче 6, но без нейрона смещения во всех слоях.


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model4 = Sequential()                                                           # Создание последовательной модели.
model4.add(Dense(100, input_dim = 8, activation = 'relu', use_bias = False))    # Добавление полносвязного слоя на 100 нейронов с relu-активацией без нейрона смещения.
model4.add(Dense(10, activation = 'sigmoid', use_bias = False))                 # Добавление полносвязного слоя на 10 нейронов с sigmoid-активацией без нейрона смещения.
model4.add(Dense(2, activation = 'softmax', use_bias = False))                  # Добавление полносвязного слоя с 2 нейронами с softmax-активацией без нейрона смещения.

print(model4.summary())                                                         # Вывод структуры модели.

Задание 8
Выведите веса модели из задачи 7 с помощью функции .get_weights().


[ ]
print(model4.get_weights())                                                     # Вывод весов модели.
[array([[-2.00454235e-01,  2.21721128e-01, -5.98642230e-03,
        -1.31997854e-01,  7.00078160e-02,  4.47021276e-02,
        -9.85549539e-02,  1.68156192e-01,  6.80439025e-02,
        -2.12743193e-01,  2.18819231e-02, -1.66671336e-01,
        -1.42523885e-01, -1.97068781e-01, -1.84926033e-01,
        -1.31501257e-01,  1.93753168e-01,  1.75194219e-01,
        -1.08809620e-01,  1.67259082e-01,  1.47439554e-01,
        -1.73151553e-01,  1.98620841e-01, -1.66308820e-01,
         5.16831726e-02,  6.97330385e-02, -5.13290763e-02,
        -4.40979600e-02, -7.16931373e-02,  9.31706578e-02,
        -6.58710301e-02,  2.15194210e-01,  8.92730504e-02,
         9.38806385e-02, -2.21989870e-01,  1.09978542e-01,
         8.86644870e-02, -1.50178879e-01,  1.32314190e-01,
         2.04385087e-01,  5.42979389e-02,  1.54279545e-01,
        -2.03471497e-01,  8.33724290e-02, -1.71808258e-01,
         1.14575997e-01,  7.71605521e-02,  7.25388974e-02,
         6.57823533e-02,  1.16506085e-01,  1.20927230e-01,
        -9.42063481e-02, -4.15742695e-02, -1.13653414e-01,
         4.92793173e-02, -3.91317755e-02,  1.57221332e-01,
        -2.62083113e-02,  1.07265130e-01,  8.50571841e-02,
        -1.81605220e-02, -1.09853283e-01, -1.76183835e-01,
        -1.26552150e-01,  9.89236981e-02,  1.39871046e-01,
        -3.37113440e-03,  1.27087429e-01,  1.60570458e-01,
         2.01909527e-01, -6.35233372e-02,  2.08393186e-02,
        -8.36396366e-02,  4.33025807e-02,  4.51920480e-02,
         1.75000861e-01,  3.54244262e-02,  2.03665212e-01,
         1.74492046e-01, -1.27640218e-01,  1.34793326e-01,
        -1.07442439e-02,  8.29660147e-02, -1.04394406e-02,
        -8.03716183e-02, -1.70966506e-01, -5.73662966e-02,
        -1.76285148e-01,  2.33565584e-01,  5.97678870e-02,
        -1.08663797e-01,  1.29626617e-01,  2.26008877e-01,
        -8.05954635e-03,  2.21538678e-01,  2.01897904e-01,
        -1.38132542e-01, -1.42369241e-01,  1.91911981e-01,
        -1.77932233e-02],
       [-5.21955043e-02,  1.31951556e-01,  1.98615775e-01,
         1.04910180e-01,  1.16731152e-01,  1.57139644e-01,
        -1.55931592e-01,  2.25519344e-01,  1.58695236e-01,
        -1.70324296e-01, -1.58169702e-01, -2.25963414e-01,
         4.61455733e-02,  3.46671790e-02, -1.97635233e-01,
         1.88201591e-01,  1.85701445e-01,  1.18803874e-01,
         6.86924011e-02,  4.80271131e-02,  4.04990762e-02,
        -1.62678689e-01, -2.32309267e-01,  1.55395254e-01,
        -1.11704998e-01,  1.47674307e-01,  8.82883817e-02,
         1.56253427e-02, -1.25877187e-01, -1.43192351e-01,
        -9.67161208e-02, -1.49912968e-01, -2.12124467e-01,
        -1.46147177e-01, -2.16500103e-01,  8.76032263e-02,
         1.44798473e-01, -2.22912267e-01, -1.01674885e-01,
        -1.64186209e-02,  1.17753744e-02, -5.41121662e-02,
        -1.74779266e-01,  1.79411322e-02, -2.06893772e-01,
         1.74598262e-01,  3.39321345e-02, -2.86989659e-02,
         1.78751752e-01,  7.80359656e-02,  1.78176925e-01,
        -1.34512395e-01, -1.21161491e-02, -1.35484636e-01,
        -1.84394985e-01, -1.87695146e-01, -2.76863724e-02,
         2.14573190e-01, -1.34110659e-01,  1.59932628e-01,
         1.03928462e-01,  1.41953722e-01, -1.08005911e-01,
         4.00600880e-02,  6.19496256e-02,  1.48650572e-01,
         1.14764854e-01,  2.29685768e-01,  1.21732280e-01,
        -7.07303882e-02,  2.18104258e-01, -5.86327910e-02,
        -8.59048814e-02, -1.77375227e-02,  6.09152764e-02,
        -2.63435245e-02, -3.35268080e-02, -8.76820236e-02,
         1.31967857e-01,  1.43991575e-01, -2.17829242e-01,
        -8.39652270e-02, -2.10978135e-01,  1.57444730e-01,
         4.74617928e-02, -8.97940993e-03,  2.22420678e-01,
        -2.08060443e-02, -1.13409244e-01, -2.04721123e-01,
        -3.16447020e-02,  1.97320536e-01, -2.12572962e-01,
        -1.30948633e-01, -7.00803697e-02, -1.84077874e-01,
         1.83994621e-02,  4.79822308e-02,  1.17272720e-01,
        -4.21481431e-02],
       [ 1.30364016e-01, -6.77826405e-02, -9.45964158e-02,
        -1.27632469e-01, -1.22443289e-02,  6.95216209e-02,
         1.80897817e-01, -1.96883157e-01,  4.61524278e-02,
        -2.26862729e-03, -1.49687856e-01,  1.36042088e-02,
         1.80618316e-02,  1.67212114e-01, -1.60660416e-01,
         1.27539292e-01, -1.02518499e-03, -1.89614847e-01,
        -2.05730170e-01, -7.67435133e-02, -1.15186386e-01,
        -1.54643357e-01,  2.09934458e-01,  1.84432521e-01,
         4.29244190e-02, -1.24828815e-02, -1.19948693e-01,
        -7.22950548e-02, -1.20469853e-01,  7.51858801e-02,
         1.12660393e-01,  1.10519275e-01, -1.06270358e-01,
         1.72157064e-01,  1.20816529e-02, -1.11163042e-01,
        -1.67555526e-01, -1.52742028e-01,  1.06489018e-01,
        -2.10565537e-01,  1.55718222e-01,  1.49116561e-01,
         1.51386425e-01,  2.60924846e-02, -1.93793625e-01,
         1.96326301e-01, -9.75255072e-02,  1.75826654e-01,
         2.34311983e-01,  8.05811137e-02, -1.68441236e-01,
        -4.93132770e-02,  1.70741662e-01, -7.73499161e-02,
         1.72665134e-01, -9.98924673e-03, -2.00142905e-01,
         9.41878706e-02,  8.38430077e-02,  1.69808701e-01,
         3.89762372e-02, -1.24748379e-01,  5.21227717e-03,
        -1.76958770e-01, -2.16341019e-01,  1.29285976e-01,
        -1.24858126e-01,  2.25203916e-01, -1.41506359e-01,
         2.17302129e-01,  1.48526683e-01, -2.08972842e-01,
         2.06315562e-01, -2.57891566e-02,  1.65956363e-01,
         2.11013868e-01,  1.49408564e-01,  9.91727263e-02,
        -1.87291056e-02, -5.80282360e-02, -8.54069889e-02,
         1.12531647e-01, -5.27479649e-02, -1.10248506e-01,
        -2.17478186e-01,  1.80631891e-01,  2.10424826e-01,
         1.84293792e-01,  1.40161023e-01, -1.31908625e-01,
         8.96951109e-02,  1.17500082e-01,  5.69511801e-02,
         2.17916295e-01, -1.59804881e-01,  1.24671504e-01,
        -1.17547840e-01,  1.54483363e-01, -6.06711209e-02,
         1.05553761e-01],
       [ 5.11604398e-02, -2.54733860e-02,  1.32244900e-01,
         1.80554971e-01, -4.78149801e-02,  9.65168029e-02,
        -6.35693073e-02,  1.84054390e-01, -7.04577565e-03,
        -4.63057309e-02,  1.82946876e-01, -4.67672944e-03,
        -1.84010565e-01, -1.05411798e-01,  1.33424997e-03,
         2.05767766e-01, -2.22646967e-01,  1.82242587e-01,
        -2.11827308e-01, -1.27626717e-01, -2.38024592e-02,
         5.21838218e-02,  8.15244764e-02,  1.63903937e-01,
         2.00879857e-01,  2.27930829e-01,  1.84091195e-01,
        -1.67062730e-02,  3.96368057e-02,  8.55019540e-02,
         1.23829290e-01,  1.62985578e-01,  1.43824205e-01,
        -5.72298020e-02, -3.10264826e-02, -2.25179717e-01,
         1.66896746e-01,  3.57660502e-02,  2.16609016e-01,
         1.31035969e-01,  7.61585087e-02,  4.94356602e-02,
        -2.13140383e-01,  6.46326989e-02,  5.57554513e-02,
         1.02456614e-01,  2.32323542e-01, -4.89146709e-02,
         1.80991486e-01,  1.50989220e-01,  1.83220655e-02,
         2.35382780e-01,  3.62839550e-02,  1.65652022e-01,
         2.09660783e-01, -1.44665509e-01,  2.80723423e-02,
        -2.25704804e-01,  2.32217386e-01, -1.97972745e-01,
        -2.29765475e-02, -1.91301227e-01, -8.77389461e-02,
         1.90696999e-01, -1.26908273e-01, -2.15484083e-01,
         1.76534280e-01, -1.20463111e-01, -1.91046163e-01,
         1.17337719e-01, -1.95858374e-01, -1.43532038e-01,
         3.66714746e-02, -1.91951528e-01, -3.39738429e-02,
        -2.97365189e-02, -2.29742184e-01, -4.62473929e-02,
         2.22592056e-03, -2.16997147e-01, -1.56438977e-01,
         9.72479582e-03,  1.53605714e-01, -7.28265494e-02,
        -1.87920660e-01,  1.97925076e-01, -1.35631531e-01,
        -1.63187534e-01,  1.04187801e-01, -2.25662321e-01,
        -1.84615850e-01, -2.14152351e-01, -1.48025632e-01,
         1.12942442e-01,  9.74550992e-02,  2.34991387e-01,
        -1.42386496e-01,  1.89639792e-01, -1.73107669e-01,
         1.47356048e-01],
       [ 1.11323372e-01, -7.20751584e-02,  1.05909064e-01,
         1.60353526e-01, -2.15686500e-01,  2.01768383e-01,
        -1.15287982e-01,  3.61335725e-02, -5.93209565e-02,
         8.53047222e-02,  1.70639768e-01,  1.35956243e-01,
        -9.66562331e-03, -1.52402550e-01, -1.68642357e-01,
        -5.85896224e-02, -6.83955699e-02,  1.15367010e-01,
        -1.08649403e-01, -1.83464229e-01,  4.30023223e-02,
         2.06064031e-01, -1.55979484e-01, -2.00711608e-01,
         1.43557683e-01,  2.74405628e-02, -1.78691506e-01,
        -4.92134690e-03,  2.31285736e-01, -2.12548867e-01,
         2.39949971e-02, -6.70618713e-02,  9.39049870e-02,
         1.98492780e-01, -1.15350135e-01, -1.84702128e-02,
        -1.18116990e-01, -2.05276847e-01,  3.48629802e-02,
        -1.29173130e-01, -1.77636042e-01, -1.30080849e-01,
         5.29115349e-02, -1.11334950e-01,  1.11495331e-01,
         1.05644003e-01, -1.16441235e-01,  2.10928395e-01,
        -1.28548503e-01, -4.51165736e-02, -1.13967098e-01,
        -2.01451316e-01,  4.40021604e-02, -5.34881651e-02,
         1.78606138e-01,  3.38439643e-03,  2.29923412e-01,
         2.94780731e-03,  1.82516769e-01,  4.02241796e-02,
        -5.13572991e-03,  6.52663410e-03, -1.97042257e-01,
        -1.10080838e-02, -1.91722482e-01, -2.16055587e-01,
         6.44980520e-02, -2.18057394e-01,  5.06330878e-02,
        -3.68780941e-02, -5.43497503e-03, -1.76792592e-02,
         1.81072697e-01, -4.62934375e-04,  6.10476285e-02,
        -1.87305883e-01, -4.94012237e-02,  2.22972050e-01,
         1.30044371e-02, -2.14592695e-01, -4.68154848e-02,
        -1.76865429e-01,  3.88320833e-02, -2.13614002e-01,
        -1.54157370e-01,  1.37470707e-01, -8.70980918e-02,
        -1.37237847e-01,  5.50150871e-03, -1.10412717e-01,
         1.93642631e-01,  1.39595076e-01,  1.18453041e-01,
        -8.85165930e-02, -1.73872724e-01,  4.71308827e-03,
         2.28653058e-01, -1.31933451e-01, -7.52746016e-02,
        -7.61935860e-02],
       [ 1.15844831e-01, -7.59022534e-02, -9.03219879e-02,
        -2.32634977e-01, -9.18196142e-02,  2.19641104e-01,
         7.71169215e-02,  1.13538936e-01,  2.10931763e-01,
        -2.24904910e-01, -2.15266377e-01, -1.99240059e-01,
        -1.16334684e-01,  4.17979062e-03, -2.03593999e-01,
        -1.00488991e-01, -1.93794355e-01,  2.72050649e-02,
         7.11113214e-03,  1.71155557e-01, -4.87859845e-02,
        -3.55982780e-03,  9.27405506e-02, -1.31223708e-01,
         1.40985414e-01,  1.69660732e-01,  1.23260602e-01,
         9.64001268e-02, -1.74474627e-01,  1.63885877e-01,
         6.05149567e-03,  3.57977301e-02, -1.84059724e-01,
         5.66333383e-02, -1.46335989e-01, -1.91348940e-02,
         1.58916220e-01,  1.37184724e-01, -2.26867497e-02,
        -5.23511022e-02,  1.60899907e-02, -5.88799864e-02,
         1.06869295e-01, -1.64784685e-01, -2.03444466e-01,
        -2.32084662e-01, -1.20808937e-01,  1.64510235e-01,
        -7.46766329e-02,  1.35227486e-01,  7.21981078e-02,
        -2.26443663e-01,  8.45809728e-02,  2.68641263e-02,
         1.51109383e-01,  9.94938165e-02,  6.75173551e-02,
         1.31410882e-01, -5.67939430e-02,  1.84957013e-01,
         5.04487008e-02,  7.22558349e-02, -7.90750682e-02,
         2.33727381e-01,  1.26140967e-01, -7.50183016e-02,
        -6.51649237e-02, -1.70654804e-02,  2.22942099e-01,
         1.58312216e-01,  9.89186764e-03,  1.43976673e-01,
        -3.06290090e-02, -6.87230825e-02,  1.13340005e-01,
        -9.81215686e-02,  2.34833375e-01,  1.74580052e-01,
        -8.74204934e-03,  5.27544171e-02,  1.40818402e-01,
        -2.16090485e-01, -8.54647011e-02, -9.22778845e-02,
        -6.23964369e-02, -2.04412490e-01,  4.14841324e-02,
        -9.22643989e-02, -2.19569519e-01, -1.22377984e-01,
         1.79939911e-01,  5.99925071e-02,  1.06259897e-01,
         3.12270969e-02,  7.73710012e-03, -2.08397403e-01,
         1.33778140e-01,  1.61654010e-01,  1.29462078e-01,
        -1.39632285e-01],
       [ 7.18093067e-02, -7.68231899e-02,  3.79840285e-02,
         7.89801031e-02, -3.97122800e-02, -1.73488259e-02,
        -1.43228769e-01,  1.12719730e-01, -9.06855166e-02,
         6.59767240e-02,  1.14426449e-01,  2.03023449e-01,
         1.46091029e-01, -2.26937011e-01,  1.93485573e-01,
         9.02684778e-02, -2.23131374e-01,  1.38017729e-01,
         7.21204430e-02,  1.47548482e-01,  8.40508938e-03,
         1.70283720e-01, -5.46645224e-02,  1.73156574e-01,
        -2.15429634e-01, -1.30616635e-01, -2.26969600e-01,
        -2.31864452e-02,  1.62279457e-02, -1.45723969e-01,
         1.70554221e-03,  1.84835121e-01,  6.04787022e-02,
         1.49343923e-01,  2.26289228e-01,  1.02835849e-01,
         1.35491386e-01, -1.56656504e-02,  1.25230715e-01,
        -1.31660074e-01,  1.66072175e-01, -2.33633190e-01,
        -9.98259932e-02,  9.88199860e-02, -3.58618051e-02,
         1.17969587e-01, -1.44961447e-01, -2.07494617e-01,
         2.07041785e-01, -1.52541190e-01, -1.25166535e-01,
         1.72089115e-01,  3.57106775e-02, -5.17638028e-02,
         2.30716631e-01,  1.60338432e-02,  1.56574145e-01,
         4.63219732e-02, -1.56607464e-01,  6.82046860e-02,
        -3.00387293e-02,  7.91932493e-02,  4.31242138e-02,
         2.92647928e-02,  1.98683783e-01, -1.47494972e-01,
         1.68765977e-01, -1.15848653e-01, -5.19181192e-02,
        -1.84881821e-01,  3.35569829e-02,  1.39516741e-02,
        -1.13643020e-01,  8.23864192e-02, -1.42969579e-01,
         1.68927774e-01,  2.19411954e-01,  2.15466723e-01,
        -8.87919962e-02, -1.22024961e-01,  1.04474559e-01,
         5.10729849e-03, -1.13609247e-01, -1.93445444e-01,
         1.56724468e-01, -6.64182603e-02, -4.62097526e-02,
        -1.12727255e-01, -2.12615177e-01, -1.21545725e-01,
         1.19968817e-01, -2.11449787e-01, -4.97155190e-02,
         1.24923602e-01, -2.18883425e-01, -3.60017270e-02,
         1.16225287e-01, -6.74130470e-02, -1.91322193e-01,
        -1.28861800e-01],
       [-4.63536084e-02, -1.04319751e-01,  6.79874271e-02,
         1.56630725e-02,  1.47578567e-02,  1.82812020e-01,
        -1.58988148e-01, -1.75083578e-02,  2.17958838e-02,
        -1.95664674e-01, -1.19002923e-01, -1.88271716e-01,
         3.79372090e-02, -1.75913692e-01, -1.71599269e-01,
         1.91690162e-01, -1.84167176e-01,  8.13753456e-02,
         2.24682555e-01,  2.15979055e-01,  1.52057454e-01,
        -5.87708652e-02, -1.36278465e-01,  5.48046678e-02,
        -6.99243695e-02,  1.88836008e-02, -2.12018996e-01,
        -1.38052285e-01, -9.95796323e-02,  9.81420279e-03,
         1.88676998e-01,  8.67839009e-02, -3.13045382e-02,
        -1.33944765e-01, -2.09545642e-01, -3.70720923e-02,
         1.18506983e-01, -3.79316062e-02, -2.14779556e-01,
         1.22097805e-01,  1.52415469e-01,  1.09422207e-02,
        -4.71411347e-02, -1.44557625e-01,  2.13241652e-01,
        -3.35549116e-02, -2.88839638e-02, -1.99668109e-01,
         2.28665769e-03, -4.37514037e-02, -2.11372852e-01,
         2.32543156e-01,  9.33327824e-02,  2.07349017e-01,
         5.60964495e-02, -1.02258593e-01, -2.08482251e-01,
         1.31949782e-04,  6.06903434e-03,  2.71481425e-02,
         4.36384529e-02, -1.65997952e-01, -2.22024038e-01,
        -2.33049542e-02,  1.93344906e-01, -1.51924998e-01,
         2.32431784e-01, -1.38690114e-01,  2.29516014e-01,
         5.90473861e-02,  1.69787630e-01, -5.05224317e-02,
        -9.24780965e-03,  1.64533213e-01,  5.46445101e-02,
        -2.65109837e-02,  2.30509028e-01, -2.31247514e-01,
        -4.13488150e-02,  1.98197171e-01, -3.16833556e-02,
        -1.44964993e-01,  3.78330797e-02,  1.38571635e-01,
         2.10187301e-01, -2.01057836e-01, -1.13299891e-01,
         1.90090224e-01,  1.21325552e-02,  3.39656919e-02,
        -1.08686328e-01, -2.23108664e-01,  1.28949687e-01,
         3.46945971e-02,  2.05937639e-01,  3.29088122e-02,
        -3.26118767e-02, -1.50839627e-01,  3.97269577e-02,
         6.43994957e-02]], dtype=float32), array([[ 1.44824386e-01,  1.41146898e-01, -1.92738295e-01,
         3.17215919e-02,  9.52766836e-02, -5.53139597e-02,
         2.18710214e-01,  5.14910817e-02,  1.27875000e-01,
        -1.94487020e-01],
       [ 1.90117270e-01,  1.06792361e-01, -1.99825138e-01,
        -7.51268268e-02,  2.12938935e-01,  2.00235069e-01,
        -2.24076346e-01,  6.35921359e-02, -6.15462363e-02,
         2.31004387e-01],
       [-8.37643147e-02,  1.36549443e-01, -1.75233588e-01,
        -1.36227876e-01, -2.27844387e-01, -1.91029355e-01,
         1.65572494e-01, -8.20468366e-02,  2.07200348e-02,
         2.12962538e-01],
       [ 1.46163493e-01,  2.88248062e-02,  2.23934650e-02,
        -3.50129902e-02, -1.47936046e-01, -3.13532501e-02,
        -2.93204933e-02,  3.04266810e-03,  1.39082998e-01,
        -1.76210493e-01],
       [-1.41620070e-01,  4.34102416e-02, -1.03957608e-01,
        -8.98533165e-02,  2.16531187e-01,  1.38445348e-01,
        -4.05135751e-03,  2.22427964e-01, -9.03555751e-03,
         1.04763448e-01],
       [-1.77517235e-02,  2.57313251e-02,  1.19828075e-01,
        -1.93279207e-01, -2.20872879e-01, -2.27987766e-01,
        -2.00731650e-01,  5.40321469e-02, -1.68174148e-01,
        -1.39490440e-01],
       [ 1.00956798e-01, -1.51005819e-01, -4.78980988e-02,
        -8.07889700e-02,  6.53376579e-02, -1.16307832e-01,
        -5.04027605e-02, -6.03938848e-02,  1.64812714e-01,
         1.01282895e-01],
       [-7.76307583e-02, -2.17019424e-01, -1.20913088e-02,
        -1.79392189e-01,  2.24614084e-01, -1.70576423e-02,
         1.51930660e-01, -1.93038315e-01,  1.82823300e-01,
        -8.20847601e-02],
       [-7.75986910e-02,  1.28359318e-01,  6.14867210e-02,
        -6.68203831e-02, -2.26213887e-01, -1.55727535e-01,
        -1.13114879e-01,  2.11078644e-01,  1.78195417e-01,
         7.89894760e-02],
       [-3.67438197e-02,  5.36093116e-02, -1.72381029e-01,
        -1.86848760e-01,  1.48943186e-01, -1.42605826e-01,
        -1.06622174e-01, -2.63812989e-02, -9.10907984e-04,
         7.99099207e-02],
       [-1.92215338e-01, -8.89270306e-02, -1.32574499e-01,
         2.07198262e-02,  2.07541138e-01,  5.72164655e-02,
         1.11169040e-01,  1.28039539e-01,  1.61831588e-01,
         7.09832609e-02],
       [-6.58224523e-03,  2.31722951e-01, -2.18275338e-01,
         1.28645599e-01,  2.14029104e-01, -1.33696049e-02,
        -2.31584474e-01, -2.12398469e-02,  2.00499892e-01,
         1.25999987e-01],
       [-9.99065787e-02,  1.39851153e-01, -1.37366593e-01,
        -5.34612387e-02, -1.81089178e-01, -1.58776328e-01,
         3.62970829e-02,  6.91872239e-02,  1.16140515e-01,
         1.13710582e-01],
       [-7.36134946e-02, -5.23509830e-02,  2.26793766e-01,
         1.40967071e-02,  1.30602151e-01, -3.17186862e-02,
         2.32454836e-02, -1.22942857e-01, -2.14449838e-01,
         2.27877855e-01],
       [ 2.00087339e-01, -4.44675982e-03, -2.17092469e-01,
         2.36062407e-02,  6.23841584e-02, -1.76434994e-01,
         1.13007188e-01,  1.62536412e-01, -4.50472683e-02,
         2.21499205e-02],
       [-2.42786109e-02, -1.42307147e-01, -1.91062927e-01,
        -3.22410464e-02, -5.71101755e-02, -9.44779217e-02,
         2.25529164e-01, -2.02650577e-02, -2.14017183e-02,
         2.13352948e-01],
       [ 1.99156165e-01, -1.86757326e-01, -1.07033670e-01,
        -7.97548890e-02,  1.85556144e-01,  9.08266604e-02,
         1.48991287e-01,  1.88214481e-02,  1.78025454e-01,
        -1.34927481e-01],
       [-8.70802701e-02,  1.86718851e-01,  5.40651083e-02,
        -8.30126554e-02, -1.21390820e-02, -7.06117600e-02,
        -1.13006800e-01,  1.31515145e-01,  1.34043783e-01,
        -6.24710172e-02],
       [-3.72701883e-02, -5.35383821e-04,  4.00148332e-02,
        -1.38023198e-01, -1.70125365e-02, -9.95317847e-02,
         1.59997404e-01, -7.27227330e-02, -1.17298201e-01,
        -1.59644186e-02],
       [ 1.73369616e-01, -1.07787281e-01, -1.26884684e-01,
         4.92391586e-02, -2.28212625e-01, -9.90353227e-02,
        -5.22702932e-03,  1.13022715e-01,  7.06065595e-02,
         1.20843917e-01],
       [-1.88338548e-01,  4.60191965e-02,  2.21567452e-01,
        -1.18701905e-02,  3.64342332e-02, -2.44072378e-02,
        -2.21717134e-01, -9.37686861e-02,  5.48987389e-02,
        -1.16750956e-01],
       [ 2.04652876e-01, -2.49761492e-02,  2.12463468e-01,
        -2.08313227e-01,  9.69009995e-02,  6.21159375e-02,
         1.87408298e-01, -1.96013495e-01, -8.96323621e-02,
         2.01630652e-01],
       [-1.63071781e-01, -1.54471278e-01,  5.39008379e-02,
        -1.96466029e-01, -9.01320130e-02, -2.17329964e-01,
         1.26499981e-01, -1.14100739e-01, -1.23099685e-02,
        -7.95015395e-02],
       [-1.14799336e-01, -6.84948117e-02, -1.69867352e-01,
         2.15175480e-01,  1.19306624e-01,  6.61229491e-02,
         4.59972024e-03,  1.82730258e-02, -1.88266098e-01,
         1.30638242e-01],
       [ 2.22913623e-02,  1.38754040e-01,  5.62846661e-02,
         9.98519659e-02, -2.30166361e-01, -1.19058773e-01,
         1.73480481e-01, -5.31713516e-02, -1.16118118e-01,
        -2.18018696e-01],
       [ 2.08496988e-01,  4.88572419e-02, -1.35390759e-01,
        -1.21905826e-01, -8.59944522e-03, -1.02611303e-01,
        -7.29831010e-02, -9.66669768e-02, -2.06232429e-01,
        -3.12006474e-03],
       [ 8.74575078e-02,  1.40483975e-01,  1.66909218e-01,
         1.47923291e-01, -1.62154436e-04, -1.03981540e-01,
         7.47209787e-03, -2.26751179e-01,  1.61336720e-01,
        -7.45111555e-02],
       [-1.43339604e-01,  4.04065847e-03,  1.88317060e-01,
         6.42327666e-02, -1.76316068e-01,  1.45710230e-01,
         1.35718793e-01, -1.76982418e-01,  5.73475361e-02,
        -2.32233703e-02],
       [-1.75610006e-01,  3.90937924e-02,  1.65808320e-01,
         2.81625390e-02, -1.93167835e-01,  1.69888496e-01,
         1.95858032e-01,  1.62631452e-01, -1.79882422e-01,
         2.15078503e-01],
       [ 1.32180542e-01,  1.60059035e-02, -1.56572074e-01,
         1.17283404e-01,  1.85060680e-01, -4.52716649e-02,
        -1.15861706e-01, -5.66742420e-02, -2.20006853e-02,
        -1.16496384e-02],
       [ 3.40798497e-02,  2.01874822e-01, -6.99746311e-02,
        -2.11784258e-01, -1.42947376e-01,  5.47010601e-02,
        -1.39316261e-01,  1.33812994e-01, -1.57100290e-01,
         1.83908343e-02],
       [-1.10725150e-01,  1.10054851e-01, -2.45160908e-02,
        -1.10622026e-01,  4.09058630e-02,  9.97034013e-02,
         1.14862800e-01,  2.14211792e-01, -8.16507638e-03,
        -1.68878436e-01],
       [ 2.25981474e-01,  1.78947896e-01, -4.17597592e-03,
        -5.02812117e-02,  3.53667438e-02,  1.42796040e-01,
        -9.02471542e-02,  1.78952962e-01,  6.10492229e-02,
         1.23112857e-01],
       [ 1.50979459e-02,  1.86708838e-01,  1.36902928e-01,
        -9.20861959e-03,  2.31259167e-01,  1.18815988e-01,
        -3.08752656e-02, -4.07617688e-02, -7.96138942e-02,
        -1.92228034e-01],
       [ 2.04014361e-01, -1.69818625e-01, -5.35224825e-02,
         4.59416807e-02,  8.32168460e-02, -1.84175208e-01,
        -1.95055753e-01,  1.30688429e-01, -1.92334354e-02,
        -9.34619904e-02],
       [ 3.32842171e-02,  1.00588948e-02,  2.21326977e-01,
        -3.36292237e-02, -6.64634556e-02,  1.01380169e-01,
        -1.67878702e-01, -2.04456478e-01, -2.08866447e-02,
         5.22058308e-02],
       [-2.13983431e-01, -1.96298152e-01,  1.32089049e-01,
         3.87310088e-02,  1.51710153e-01,  2.10546255e-01,
        -2.20032737e-01, -1.85733944e-01, -3.41556966e-03,
         1.92724884e-01],
       [-3.46699804e-02,  1.15431279e-01, -1.40021920e-01,
         2.09174186e-01,  1.89270556e-01, -1.09929338e-01,
         5.02696931e-02, -8.05465877e-03, -2.04196170e-01,
        -1.68863446e-01],
       [ 1.06708825e-01,  4.56989706e-02,  1.83132440e-01,
        -1.56408146e-01, -3.58531773e-02, -2.24666864e-01,
         1.22537613e-01, -9.22135264e-02,  9.79506671e-02,
         5.51671982e-02],
       [-6.63819909e-03,  1.51605517e-01, -6.75544143e-04,
         1.67276710e-01, -1.48610249e-01, -2.22689077e-01,
        -1.39384717e-02,  5.03410697e-02,  2.28836477e-01,
         5.39547205e-03],
       [ 9.00684297e-02, -2.15149820e-01, -1.64658457e-01,
         2.99161375e-02,  1.59623921e-01,  9.83356237e-02,
         2.08350420e-01,  1.21368617e-02,  1.51154608e-01,
         1.02662146e-01],
       [-1.68746457e-01,  9.05139446e-02,  1.89629555e-01,
        -1.37140304e-01,  2.15409845e-01,  6.85840249e-02,
         9.75664556e-02,  2.23424137e-01,  4.84010279e-02,
        -8.36641341e-02],
       [ 1.96421027e-01, -1.12849832e-01,  1.66994810e-01,
        -1.99268639e-01,  2.17460096e-02, -1.34015679e-02,
        -1.71147883e-01,  7.23142624e-02,  7.15573430e-02,
        -1.68777138e-01],
       [-1.34518042e-01,  2.03854054e-01,  1.39364779e-01,
        -5.94226122e-02,  9.26368237e-02, -5.36735505e-02,
         4.35110331e-02,  5.12307882e-03, -3.80976349e-02,
        -6.52634948e-02],
       [-8.73862952e-02,  1.87353015e-01, -1.56835958e-01,
        -1.70421779e-01,  1.59199178e-01,  1.54136509e-01,
         7.96873569e-02,  5.62958717e-02, -9.12877023e-02,
         1.61273301e-01],
       [ 2.24402428e-01, -2.30447605e-01,  1.33959651e-01,
         1.12334043e-02,  1.66234553e-01,  6.14101589e-02,
         2.00469226e-01, -1.74090207e-01,  1.71238810e-01,
         5.67819178e-02],
       [-1.70810342e-01,  2.24318296e-01, -1.70653760e-02,
         8.96745920e-03, -2.29263574e-01,  1.47258550e-01,
        -1.90830901e-01, -1.39193773e-01, -1.87416553e-01,
        -2.30750471e-01],
       [-4.17601019e-02,  6.27213717e-03,  1.66194260e-01,
         1.97515756e-01,  2.09327757e-01, -1.45136982e-01,
        -1.32696211e-01,  5.52249849e-02, -1.55814901e-01,
         7.73347616e-02],
       [-2.96681225e-02,  1.32107824e-01,  8.84920955e-02,
         2.09345222e-02,  2.06353188e-01, -1.56557322e-01,
        -7.04330653e-02, -1.60161540e-01, -1.08456478e-01,
        -5.35070151e-02],
       [ 1.30232424e-01, -4.23909873e-02, -1.83581635e-01,
         9.40497220e-02, -1.24863125e-01,  2.04910904e-01,
        -8.17466527e-02, -1.07147217e-01, -1.09776266e-01,
        -6.94740415e-02],
       [-2.04147220e-01,  2.47001648e-03,  2.27528960e-01,
        -8.36968273e-02,  1.27097219e-01, -1.36200547e-01,
         1.59361452e-01, -1.55740067e-01,  1.78090781e-01,
         2.04032302e-01],
       [ 7.05008209e-02, -2.06783399e-01, -5.74388057e-02,
        -3.72877866e-02,  1.63126796e-01,  1.25379652e-01,
         7.03641176e-02, -2.17992142e-01, -1.23323336e-01,
         7.06717670e-02],
       [-2.29727358e-01,  1.33403122e-01,  1.85915232e-02,
        -7.66789764e-02,  6.50684536e-03,  6.73586130e-03,
         1.03231788e-01, -5.71253151e-02, -1.00795329e-01,
        -4.83776927e-02],
       [ 1.49942279e-01, -2.08874732e-01,  6.75496459e-02,
         2.13947177e-01,  1.85708255e-01,  1.17523998e-01,
         2.17580378e-01, -1.81548610e-01, -1.90436438e-01,
        -1.18152484e-01],
       [-6.47077858e-02, -6.05448484e-02,  1.20977372e-01,
        -7.29128867e-02, -5.62238693e-03, -2.04813853e-01,
        -1.78384781e-02,  8.97275209e-02,  2.30542421e-01,
         1.05967194e-01],
       [-1.66963160e-01,  1.93320304e-01, -1.29800498e-01,
         7.98232853e-03,  8.37791860e-02,  3.40207815e-02,
        -3.78041267e-02, -2.28316128e-01,  6.10946417e-02,
        -1.07093260e-01],
       [ 8.54606330e-02, -1.03393644e-02, -9.76822823e-02,
         1.79872066e-01, -2.09342122e-01,  1.45341665e-01,
         9.96401310e-02,  2.10263431e-02,  2.00128257e-02,
         4.04938757e-02],
       [-2.18485489e-01, -1.78578496e-01, -9.03513432e-02,
        -1.06199935e-01,  1.11060083e-01,  1.77435279e-01,
        -7.90108740e-03,  8.70937109e-03,  9.44907367e-02,
        -1.14649437e-01],
       [-1.96852133e-01, -1.14619702e-01, -2.17442662e-02,
        -1.96143121e-01, -2.10246295e-01, -1.75068319e-01,
         7.96627998e-03, -1.33813500e-01, -1.51134059e-01,
        -2.11238235e-01],
       [ 1.20652080e-01,  1.57022536e-01, -1.32959366e-01,
        -4.00473028e-02, -1.52494490e-01, -1.52271032e-01,
        -1.48710087e-01, -5.21481335e-02, -6.57051802e-04,
        -3.12834829e-02],
       [ 9.59521234e-02,  1.45296812e-01, -1.08623244e-01,
         1.19714051e-01, -1.63893044e-01, -1.90432206e-01,
        -8.50633383e-02,  1.20436043e-01,  1.93725884e-01,
         8.29119980e-03],
       [-5.23365587e-02, -7.96996057e-03,  1.65387064e-01,
        -2.07497478e-01,  1.84140235e-01, -1.55198157e-01,
        -2.29181722e-01, -9.77683663e-02,  1.25129908e-01,
        -1.91690683e-01],
       [ 1.49439126e-01,  1.11509711e-01, -1.44724220e-01,
        -1.92177519e-01,  2.11328983e-01, -1.74445242e-01,
         1.60932481e-01, -6.69574738e-02, -3.01072448e-02,
         8.69387090e-02],
       [-1.16003007e-02,  1.35218978e-01, -1.20191969e-01,
        -2.16171712e-01,  3.92919183e-02,  1.83250874e-01,
        -2.27774292e-01,  1.47408396e-01, -5.21030873e-02,
        -1.66555971e-01],
       [ 2.24339902e-01,  1.07166469e-01,  1.19840115e-01,
         1.26920044e-01, -9.94817317e-02,  1.75432265e-01,
        -1.30175292e-01, -1.67457134e-01, -2.14288026e-01,
        -8.66773427e-02],
       [-4.96429205e-02,  2.02883065e-01,  1.71646088e-01,
        -2.25844711e-01, -2.03767464e-01,  1.61823988e-01,
        -2.22588286e-01, -1.57972381e-01, -1.89486608e-01,
        -6.96879774e-02],
       [-1.43796772e-01, -2.18405694e-01,  7.55517483e-02,
        -1.29426420e-01,  8.00486803e-02, -1.67145476e-01,
        -1.74647361e-01,  2.25274146e-01,  2.13842511e-01,
         1.88059807e-01],
       [-2.05574974e-01,  9.54340398e-02,  1.95434719e-01,
         1.18206263e-01, -6.88863099e-02, -2.21366107e-01,
        -6.73258156e-02,  4.37822044e-02,  1.12881362e-02,
         1.37047529e-01],
       [ 1.86929762e-01, -2.20399350e-01, -1.65076137e-01,
        -2.09692761e-01, -2.58472562e-03,  1.54443949e-01,
        -1.67408630e-01,  6.96273446e-02, -3.40922177e-03,
        -4.85351682e-03],
       [ 1.73708379e-01,  3.10131311e-02,  5.28320670e-04,
        -5.41262031e-02, -1.82144642e-01,  1.74511611e-01,
         1.21707588e-01,  1.10716313e-01,  1.77638084e-01,
         1.80278271e-01],
       [ 2.13218480e-01, -1.44004673e-01,  6.41213357e-03,
        -1.02614760e-01, -2.61130184e-02,  1.06970042e-01,
        -7.54186064e-02,  1.81819439e-01,  1.91684276e-01,
         1.83474779e-01],
       [ 1.49364799e-01, -2.13479623e-01,  8.96973908e-02,
         2.26117015e-01, -7.10325390e-02,  1.56292260e-01,
        -1.05497062e-01,  3.35977674e-02,  1.96149051e-02,
        -2.30976149e-01],
       [-1.06557593e-01,  4.63108718e-02,  8.75661075e-02,
         6.03774488e-02,  1.17875904e-01,  6.00877404e-02,
        -2.27609023e-01,  8.77362490e-02,  1.07647687e-01,
        -1.04992136e-01],
       [-7.96985924e-02, -1.92216784e-01,  2.02933282e-01,
        -2.07096890e-01, -1.67170316e-01,  9.72761512e-02,
         8.31852257e-02,  2.27460861e-01, -9.48312879e-02,
         1.81956887e-01],
       [-1.54745907e-01,  1.73484683e-02, -1.31328434e-01,
        -1.83517709e-01,  5.02950251e-02, -1.84219807e-01,
        -1.71469226e-01, -1.63843051e-01, -2.03987628e-01,
        -1.94423050e-02],
       [-1.58436894e-01, -1.91814750e-01,  4.72845435e-02,
         1.10104352e-01, -6.93309903e-02,  2.19086587e-01,
         1.61449879e-01, -1.59381211e-01, -2.00747848e-01,
        -1.52849808e-01],
       [ 1.21093750e-01, -1.96347371e-01,  1.76843822e-01,
        -7.96035975e-02,  3.54116261e-02,  2.42316127e-02,
         1.95121020e-01,  1.32361025e-01,  8.95707905e-02,
         8.15076530e-02],
       [-1.96603954e-01, -5.47551364e-02,  6.16145730e-02,
         1.18821114e-01, -1.82027653e-01, -2.24642083e-01,
         1.75424308e-01,  8.82134736e-02,  3.84784341e-02,
         3.99916172e-02],
       [-1.01943955e-01,  1.79490030e-01, -9.63114947e-02,
        -7.19156116e-02,  2.22855628e-01, -6.01996630e-02,
         5.75315654e-02,  8.86827707e-02,  1.50882542e-01,
         4.57814336e-02],
       [-4.21834588e-02, -2.13350877e-01, -1.52102768e-01,
         7.01025426e-02,  4.64316905e-02,  1.26635492e-01,
        -1.72787398e-01,  1.21484131e-01, -1.76226526e-01,
        -6.47112429e-02],
       [-1.47384286e-01, -3.26690823e-02,  1.53183192e-01,
        -1.70436814e-01, -5.12898415e-02, -1.83304012e-01,
        -4.89060730e-02, -3.76125276e-02, -1.84998035e-01,
        -6.35964125e-02],
       [ 1.10281020e-01,  1.91996992e-02,  2.12459117e-01,
         1.31763160e-01, -4.51203734e-02, -2.58529186e-02,
        -9.61439461e-02,  1.01900905e-01,  1.03124082e-02,
         1.61661863e-01],
       [-1.84746236e-01,  2.25630224e-01,  5.32966852e-02,
        -5.19959480e-02,  2.29953915e-01, -9.68504399e-02,
        -1.60576165e-01,  2.06646144e-01, -1.05223715e-01,
        -2.17503026e-01],
       [ 1.32737190e-01, -8.35484266e-03,  6.65946305e-02,
         1.94675237e-01, -2.11599335e-01,  9.05045271e-02,
         1.89308465e-01, -1.08361363e-01, -2.19829157e-01,
        -1.55241042e-01],
       [ 1.95918620e-01, -1.64071351e-01, -1.04135960e-01,
        -1.07410148e-01, -1.56082690e-01,  2.04892188e-01,
        -1.69481024e-01,  4.04361486e-02,  5.46664298e-02,
        -1.31550550e-01],
       [ 2.06507117e-01, -1.05026931e-01,  1.00053757e-01,
         1.85548335e-01, -1.46356657e-01, -5.19610345e-02,
         1.62748724e-01,  2.80893445e-02,  2.73323953e-02,
         6.97717667e-02],
       [ 6.56240284e-02,  1.12732410e-01, -2.71237642e-02,
         5.08454442e-03,  1.79702282e-01, -5.18290699e-02,
        -8.44719261e-02, -3.63046527e-02, -1.70449287e-01,
        -1.38672084e-01],
       [-1.63085654e-01, -2.28695273e-01,  1.47510022e-01,
         7.97790587e-02,  5.03799319e-02,  6.23906553e-02,
         2.28458911e-01, -4.77306098e-02, -2.07522258e-01,
        -4.48312163e-02],
       [-1.75108910e-02,  1.12897038e-01,  1.60884291e-01,
         1.50237560e-01,  6.95891380e-02, -7.38327652e-02,
         1.74295843e-01,  1.36734366e-01, -2.24381551e-01,
         4.29671407e-02],
       [-5.12878299e-02, -1.18567765e-01, -1.58819035e-01,
        -8.07444304e-02, -8.63946527e-02, -1.47492364e-01,
         1.62836194e-01,  1.84161574e-01, -1.29150629e-01,
         1.99757427e-01],
       [ 1.68747008e-01, -7.17224032e-02,  5.19409478e-02,
        -1.29119337e-01,  4.32625711e-02, -2.28262290e-01,
         1.23523623e-01,  2.28635907e-01,  2.09772706e-01,
         1.13878459e-01],
       [ 1.06092095e-01,  1.16328150e-01,  2.19424635e-01,
        -6.43015206e-02,  1.51808977e-01,  6.16689026e-02,
         4.16058004e-02, -1.71433195e-01, -8.60451311e-02,
         2.01564729e-02],
       [-1.43450364e-01, -8.77988487e-02,  1.60791308e-01,
         1.64325982e-01, -2.06693709e-02, -1.23480529e-01,
        -1.93201870e-01,  1.32624120e-01, -1.67005435e-01,
        -2.24687636e-01],
       [ 6.89528883e-03,  1.29504651e-01,  8.40861499e-02,
         2.04697907e-01,  7.69025385e-02,  6.61044717e-02,
         1.40683264e-01, -1.72438994e-01, -1.14634290e-01,
         2.07181156e-01],
       [-9.18931365e-02,  6.11619651e-02, -3.13520432e-05,
        -2.22136542e-01,  2.25234985e-01, -1.22539997e-01,
         8.42261314e-02,  1.93500668e-01,  8.85313451e-02,
        -8.28345269e-02],
       [ 1.82082444e-01, -1.89922094e-01, -1.03839442e-01,
        -1.48331672e-02, -9.75053757e-02,  1.53567821e-01,
        -1.78752735e-01,  1.40027493e-01, -4.42821383e-02,
         3.61729562e-02],
       [ 2.11076438e-03,  2.00333416e-01, -3.29733342e-02,
        -4.06187773e-02, -3.25626135e-03,  2.24273026e-01,
         6.95464909e-02,  1.44830555e-01, -1.50766388e-01,
         1.36368275e-01],
       [ 1.34585708e-01, -8.08175951e-02,  2.26233333e-01,
         1.57556266e-01, -1.52908117e-01,  1.58261389e-01,
        -1.67808384e-01, -1.44956023e-01, -1.63544714e-02,
        -9.53232348e-02],
       [-4.76235896e-02, -7.78921992e-02, -6.56099468e-02,
         3.83719206e-02,  2.93653905e-02,  2.16852248e-01,
         2.00148642e-01, -1.47412345e-01, -1.88470960e-01,
         7.98985958e-02],
       [ 9.11905468e-02,  1.09737456e-01,  2.02781439e-01,
         1.48559809e-01,  2.19795793e-01, -2.03822419e-01,
        -1.92082971e-01,  1.18801922e-01,  7.83053637e-02,
         1.01745099e-01]], dtype=float32), array([[-0.03077984, -0.50741434],
       [ 0.49332243,  0.22764558],
       [-0.31586653,  0.6413358 ],
       [-0.00411946, -0.10207915],
       [ 0.03833646,  0.25248712],
       [-0.25814742, -0.6233932 ],
       [-0.2502454 , -0.43069863],
       [-0.5999734 , -0.33522102],
       [-0.2332786 , -0.47455716],
       [-0.32667482,  0.6318466 ]], dtype=float32)]
Задание 9
Задайте значения весов для модели следующей структуры:

размерность входных данных равна 2
количество нейронов на первом скрытом слое равно 2
количество нейронов на втором скрытом слое равно 2
количество нейронов на выходном слое равно 1
нейрон смещения отключен на всех слоях.
Пример нейронной сети:

image.png

Значения весов заданной модели:

image.png


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.
import numpy as np                                                              # Работа с массивами.

model5 = Sequential()                                                           # Создание последовательной модели.
model5.add(Dense(2, inpu…      # Вывод структуры модели.

w1, w2, w3, w4, w5, w6, w7, w8, w9, w10 = -0.1, 0.2, -0.5, 0.8, 0.3, 0.4, -0.3, 0.5, 0.9, 0.1            # Задаём значения весов.

new_weights = [np.array([[w1, w2], [w3, w4]]), np.array([[w5, w6], [w7, w8]]), np.array([[w9], [w10]])]  # Формируем список весов.

model5.set_weights(new_weights)                                                 # Меняем веса модели.

print(model5.get_weights())                                                     # Вывод весов модели.

Задание 10
Создайте модель для реализации структуры из задачи 9.


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model6 = Sequential()                                                           # Создание последовательной модели.
model6.add(Dense(2, input_dim = 2, use_bias = False))                           # Добавление полносвязного слоя на 2 нейрона без нейрона смещения.
model6.add(Dense(2, use_bias = False))                                          # Добавление полносвязного слоя на 2 нейрона без нейрона смещения.
model6.add(Dense(1, use_bias = False))                                          # Добавление полносвязного слоя с 1 нейроном без нейрона смещения.

model6.summary()                                                                # Вывод структуры модели.

Задание 11
Создайте входной вектор из числовых значений, который можно использовать для формирования модели из задачи 10.

Пример создания входного вектора размерностью (1, 3): x1 = 5 x2 = 1 x3 = 6 x_train = np.expand_dims(np.array([x1, x2, x3]), 0)


[ ]
import numpy as np                                                              # Работа с массивами.

x1 = 0.8                                                                        # Первый элемент вектора.
x2 = -0.1                                                                       # Второй элемент вектора.

x_train = np.expand_dims(np.array([x1, x2]), 0)                                 # Формируем вектор.

print(x_train.shape)                                                            # Выводим размерность вектора на экран.
(1, 2)
Так как размерность входных данных рассматриваемой модели равна 2, то в нашем векторе будет 2 элемента x1 и x2.

Задание 12
Задайте созданные в задаче 9 веса в модель из задания 10 с помощью функции .set_weights().


[ ]
model6.set_weights(new_weights)                                                 # Меняем веса модели №6 (из задания 10).

print(model6.get_weights())                                                     # Вывод весов модели №6 (из задания 10).
[array([[-0.1,  0.2],
       [-0.5,  0.8]], dtype=float32), array([[ 0.3,  0.4],
       [-0.3,  0.5]], dtype=float32), array([[0.9],
       [0.1]], dtype=float32)]
Задание 13
Получите значения выхода сети с помощью функции .predict(), воспользовавшись вектором из задачи 11.


[ ]
print(model6.predict(x_train))                                                  # Получаем значение выхода сети модели №6.
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 140ms/step
[[-0.0269]]
Задание 14
Создайте нейронную сеть, содержащую три слоя, для классификации цифр от 0 до 5 включительно, с размерностью входных данных 256. Отобразите структуру модели.


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model7 = Sequential()                                                           # Создание последовательной модели.
model7.add(Dense(128, input_dim = 256, activation = 'relu'))                    # Добавление полносвязного скрытого слоя на 128 нейронов с функцией активации 'relu'.
model7.add(Dense(64, activation = 'relu'))                                      # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model7.add(Dense(6, activation = 'softmax'))                                    # Добавление полносвязного слоя на 128 нейронов с функцией активации 'softmax'.

model7.summary()                                                                # Вывод структуры модели.

В скрытых слоях используем функцию активации 'relu', а на выходном слое 'softmax', т.к. она хорошо подходит для классификации элементов.

Задание 15
Создайте нейронную сеть для классификации 5-и видов диких животных по фотографии 25х25. Постройте архитектуру нейронной сети, содержащую шесть слоев.


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense, Flatten                              # Подключение класса Dense - полносвязный слой, и Flatten - преобразование массивов.

model8 = Sequential()                                                           # Создание последовательной модели.
model8.add(Flatten(input_shape = (25, 25, 3)))                                  # Преобра…олносвязного скрытого слоя на 128 нейронов с функцией активации 'relu'.
model8.add(Dense(64, activation = 'relu'))                                      # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model8.add(Dense(5, activation = 'softmax'))                                    # Добавление полносвязного слоя на 5 нейронов с функцией активации 'softmax'.

model8.summary()                                                                # Вывод структуры модели.

Здесь аналогично в скрытых слоях используем функцию активации relu, а на выходном слое softmax, т.к. она хорошо подходит для классификации элементов. Нейронов в выходном слое 5, т.к. по условию классификация 5-ти видов животных.

Задание 16
Создайте нейронную сеть, использующую температуру тела и давление для отличия больного человека от здорового. Постройте архитектуру нейронной сети, содержащую четыре слоя, на выходном слое используйте функцию активации linear. И предусмотрите нормализацию входных данных


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense, BatchNormalization                   # Подключение класса Dense - полносвязный слой, и BatchNormalization - нормализация.

model9 = Sequential()                                                           # Создание последовательной модели.
model9.add(BatchNormalization(input_shape = (2,)))                              # Нормали…язного скрытого слоя на 32 нейрона с функцией активации 'relu'.
model9.add(Dense(16, activation = 'relu'))                                      # Добавление полносвязного скрытого слоя на 16 нейронов с функцией активации 'relu'.
model9.add(Dense(1, activation = 'linear'))                                     # Добавление полносвязного выходного слоя на 1 нейрон с функцией активации 'linear'.

model9.summary()                                                                # Вывод структуры модели.

Здесь в выходном слое используем активационную функцию linear, по условию задачи. Нейронов в выходном слое 1, т.к. нейросеть должна ответить на вопрос, болен человек или нет. Входные данные нормализуются с помощью BatchNormalization. В остальных скрытых слоях используем активационные функции relu.

Задание 17
Создайте нейронную сеть, отличающую мак от розы по изображению 12 на 12 пикселей. Постройте архитектуру нейронной сети, содержащую два слоя, на выходном слое используйте функцию активации sigmoid.


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense, Flatten                              # Подключение класса Dense - полносвязный слой, и Flatten - преобразование массивов.

model10 = Sequential()                                                          # Создание последовательной модели.
model10.add(Flatten(input_shape = (12, 12, 3)))                                 # Преобразование изображения в вектор.
model10.add(Dense(64, activation = 'relu'))                                     # Добавление полносвязного скрытого слоя на 64 нейрона с функцией активации 'relu'.
model10.add(Dense(1, activation = 'sigmoid'))                                   # Добавление полносвязного выходного слоя на 1 нейрон с функцией активации 'linear'.

model10.summary()                                                               # Вывод структуры модели.

Здесь в выходном слое используем активационную функцию sigmoid, т.к. того требует условие задачи. Нейронов в выходном слое 1, т.к. необходимо отличить из двух объектов один. Вводные данные, т.е. картинки, преобразовываем в вектор.

Задание 18
Создайте нейронную сеть для классификации пресмыкающихся по трем категориям. Известно, что каждая категория характеризуется 8-ю числовыми признаками. Постройте архитектуру нейронной сети, содержащую три слоя с различными активационными функциями для решения поставленной задачи.


[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model11 = Sequential()                                                          # Создание последовательной модели.
model11.add(Dense(64, input_dim = 8, activation = 'relu'))                      # Добавление полносвязного скрытого слоя на 64…о скрытого слоя на 32 нейрона с функцией активации 'sigmoid'.
model11.add(Dense(16, activation = 'tanh'))                                     # Добавление полносвязного скрытого слоя на 16 нейронов с функцией активации 'tanh'.
model11.add(Dense(3, activation = 'softmax'))                                   # Добавление полносвязного выходного слоя на 3 нейрона с функцией активации 'softmax'.

model11.summary()                                                               # Вывод структуры модели.

Здесь, аналогично другим примерам, в выходном слое используем активационную функцию softmax, т.к. по условию происходит классификация. Нейронов в выходном слое 3, т.к. классификация по 3-м категорям. Размерность вводных данных 8, т.к. объекты характеризуются 8-ю числовыми признаками. В остальных скрытых слоях используем различные активационные функции, как это требовалось по условию.

Задание 19
Создайте систему компьютерного зрения, которая будет определять тип геометрической фигуры. Используя подготовленную базу и шаблон ноутбука проведите серию экспериментов по перебору гиперпараметров нейронной сети, распознающей три категории изображений (треугольник, круг, квадрат).

Поменяйте количество нейронов в сети, используя следующие значения:
один слой 10 нейронов
один слой 100 нейронов
один слой 5000 нейронов.
Поменяйте активационную функцию в скрытых слоях с relu на linear.
Поменяйте размеры batch_size:
10
100
1000
Выведите на экран получившиеся точности.

[ ]
# Подключение класса для создания нейронной сети прямого распространения
from tensorflow.keras.models import Sequential
# Подключение класса для создания полносвязного слоя
from tensorflow.keras.layers import Dense
# Подключение оптимизатора
from tensorflow.keras.optimizers import Adam
# Подключение утилит для to_categorical
from tensorflow.keras import utils
# Подключение библиотеки для загрузки изображений
from tensorflow.keras.preprocessing import image
# Подключение библиотеки для работы с массивами
import numpy as np
# Подключение библиотек для отрисовки изображений
import matplotlib.pyplot as plt
# Подключение модуля для работы с файлами
import os
# Вывод изображения в ноутбуке, а не в консоли или файле
%matplotlib inline

[ ]
# Загрузка датасета из облака
import gdown
gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l3/hw_light.zip', None, quiet=True)


[ ]
# Распаковываем архив hw_light.zip в папку hw_light
!unzip -q hw_light.zip
replace hw_light/0/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: 

[ ]
# Путь к директории с базой
base_dir = '/content/hw_light'
# Создание пустого списка для загрузки изображений обучающей выборки
x_train = []
# Создание списка для меток классов
y_train = []
# Задание высоты и ширины загружаемых изображений
img_height = 20
img_width = 20
# Перебор папок в директории базы
for patch in os.listdir(base_dir):
    # Перебор файлов в папках
    for img in os.listdir(base_dir + '/' + patch):
        # Добавление в список изображений текущей картинки
        x_train.append(image.img_to_array(image.load_img(base_dir + '/' + patch + '/' + img,
                                                    target_size=(img_height, img_width),
                                                    color_mode='grayscale')))
        # Добавление в массив меток, соответствующих классам
        if patch == '0':
            y_train.append(0)
        elif patch == '3':
            y_train.append(1)
        else:
            y_train.append(2)

# Преобразование в numpy-массив загруженных изображений и меток классов
x_train = np.array(x_train)
y_train = np.array(y_train)
# Вывод размерностей
print('Размер массива x_train', x_train.shape)
print('Размер массива y_train', y_train.shape)
Размер массива x_train (302, 20, 20, 1)
Размер массива y_train (302,)

[ ]
from tensorflow.keras.models import Sequential                                  # Подключение класса создания модели Sequential.
from tensorflow.keras.layers import Dense                                       # Подключение класса Dense - полносвязный слой.

model11 = Sequential()                                                          # Создание последовательной модели.
model11.add(Dense(64, input_dim = 8, activation = 'relu'))                      # Добавление полносвязного скрытого слоя на 64…о скрытого слоя на 32 нейрона с функцией активации 'sigmoid'.
model11.add(Dense(16, activation = 'tanh'))                                     # Добавление полносвязного скрытого слоя на 16 нейронов с функцией активации 'tanh'.
model11.add(Dense(3, activation = 'softmax'))                                   # Добавление полносвязного выходного слоя на 3 нейрона с функцией активации 'softmax'.

model11.summary()                                                               # Вывод структуры модели.

[ ]
from tensorflow.keras.layers import Flatten
from sklearn.model_selection import train_test_split

y_train = utils.to_categorical(y_train, 3)
x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)

def func(n, b):
    model12 = Sequential()                                                      # Создание последовательной модели.
    model12.add(Flatten(input_shape = (20, 20, 1)))
    model12.add(Dense(n, activation = 'relu'))                                  # Добавление полносвязного скрытого слоя на n нейронов с функцией активации 'relu'.
…        accuracy = func(i, j)
        acc[f'нейронов - {i} и batch_size = {j}'] = accuracy
for i, j in acc.items():
    print(f'Точность для {i}: {j}')
Epoch 1/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 2s 27ms/step - accuracy: 0.4546 - loss: 62.3602 - val_accuracy: 0.5574 - val_loss: 41.4664
Epoch 2/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.5252 - loss: 26.0394 - val_accuracy: 0.5902 - val_loss: 33.5822
Epoch 3/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.5965 - loss: 26.8475 - val_accuracy: 0.5738 - val_loss: 26.7832
Epoch 4/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.5985 - loss: 19.9744 - val_accuracy: 0.5574 - val_loss: 26.0682
Epoch 5/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.5901 - loss: 20.5257 - val_accuracy: 0.5574 - val_loss: 25.3418
Epoch 1/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 2s 433ms/step - accuracy: 0.3547 - loss: 137.9727 - val_accuracy: 0.3770 - val_loss: 49.8350
Epoch 2/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.4994 - loss: 32.4864 - val_accuracy: 0.3934 - val_loss: 45.9551
Epoch 3/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.5056 - loss: 39.2981 - val_accuracy: 0.4098 - val_loss: 42.5049
Epoch 4/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.5418 - loss: 34.9775 - val_accuracy: 0.4262 - val_loss: 32.0869
Epoch 5/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.5418 - loss: 25.8254 - val_accuracy: 0.5902 - val_loss: 23.5751
Epoch 1/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step - accuracy: 0.2614 - loss: 59.7716 - val_accuracy: 0.3934 - val_loss: 20.2328
Epoch 2/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 527ms/step - accuracy: 0.3402 - loss: 32.0468 - val_accuracy: 0.3443 - val_loss: 7.9745
Epoch 3/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.3195 - loss: 17.4860 - val_accuracy: 0.5410 - val_loss: 7.0432
Epoch 4/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.4813 - loss: 11.5824 - val_accuracy: 0.4754 - val_loss: 7.1075
Epoch 5/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.4979 - loss: 7.8483 - val_accuracy: 0.4918 - val_loss: 5.7706
Epoch 1/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 3s 53ms/step - accuracy: 0.4054 - loss: 144.6125 - val_accuracy: 0.6393 - val_loss: 70.4311
Epoch 2/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5731 - loss: 61.2476 - val_accuracy: 0.6557 - val_loss: 52.7017
Epoch 3/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.6462 - loss: 38.5499 - val_accuracy: 0.7049 - val_loss: 40.6675
Epoch 4/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7889 - loss: 13.7925 - val_accuracy: 0.6885 - val_loss: 18.7253
Epoch 5/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8181 - loss: 11.2862 - val_accuracy: 0.7049 - val_loss: 34.0792
Epoch 1/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 2s 426ms/step - accuracy: 0.3518 - loss: 128.3809 - val_accuracy: 0.3770 - val_loss: 72.3945
Epoch 2/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - accuracy: 0.4744 - loss: 51.7073 - val_accuracy: 0.5246 - val_loss: 64.0300
Epoch 3/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.5551 - loss: 52.9870 - val_accuracy: 0.6557 - val_loss: 37.3333
Epoch 4/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - accuracy: 0.7123 - loss: 23.4477 - val_accuracy: 0.6393 - val_loss: 40.6105
Epoch 5/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.6183 - loss: 30.8409 - val_accuracy: 0.6393 - val_loss: 38.9617
Epoch 1/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step - accuracy: 0.3320 - loss: 317.9490 - val_accuracy: 0.2295 - val_loss: 118.9330
Epoch 2/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.3237 - loss: 118.3318 - val_accuracy: 0.3443 - val_loss: 170.0596
Epoch 3/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3195 - loss: 149.0671 - val_accuracy: 0.4262 - val_loss: 169.4248
Epoch 4/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.4066 - loss: 147.7169 - val_accuracy: 0.4262 - val_loss: 132.0451
Epoch 5/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.4191 - loss: 112.8522 - val_accuracy: 0.4918 - val_loss: 80.2617
Epoch 1/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 2s 25ms/step - accuracy: 0.4467 - loss: 716.7605 - val_accuracy: 0.5574 - val_loss: 55.9082
Epoch 2/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7532 - loss: 25.2712 - val_accuracy: 0.7213 - val_loss: 29.5925
Epoch 3/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.6640 - loss: 36.6942 - val_accuracy: 0.4918 - val_loss: 58.6465
Epoch 4/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.6375 - loss: 55.5563 - val_accuracy: 0.7213 - val_loss: 25.4430
Epoch 5/5
25/25 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7445 - loss: 16.7321 - val_accuracy: 0.7213 - val_loss: 20.6825
Epoch 1/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 2s 379ms/step - accuracy: 0.3734 - loss: 802.5624 - val_accuracy: 0.4426 - val_loss: 1131.5428
Epoch 2/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.4828 - loss: 727.0295 - val_accuracy: 0.4426 - val_loss: 301.0219
Epoch 3/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step - accuracy: 0.3771 - loss: 315.0587 - val_accuracy: 0.4426 - val_loss: 207.5188
Epoch 4/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - accuracy: 0.5164 - loss: 136.4598 - val_accuracy: 0.4590 - val_loss: 156.9753
Epoch 5/5
3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.5605 - loss: 102.9463 - val_accuracy: 0.3934 - val_loss: 98.6015
Epoch 1/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step - accuracy: 0.3237 - loss: 45.7129 - val_accuracy: 0.3607 - val_loss: 1914.3497
Epoch 2/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 246ms/step - accuracy: 0.3320 - loss: 1926.1139 - val_accuracy: 0.4426 - val_loss: 948.0874
Epoch 3/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.4025 - loss: 920.6962 - val_accuracy: 0.3115 - val_loss: 1038.9999
Epoch 4/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3361 - loss: 960.5919 - val_accuracy: 0.4754 - val_loss: 491.7029
Epoch 5/5
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 137ms/step - accuracy: 0.4855 - loss: 444.4778 - val_accuracy: 0.4590 - val_loss: 663.1367
Точность для нейронов - 10 и batch_size = 10: 0.6016597747802734
Точность для нейронов - 10 и batch_size = 100: 0.5560166239738464
Точность для нейронов - 10 и batch_size = 1000: 0.4979253113269806
Точность для нейронов - 100 и batch_size = 10: 0.7800830006599426
Точность для нейронов - 100 и batch_size = 100: 0.6265560388565063
Точность для нейронов - 100 и batch_size = 1000: 0.41908714175224304
Точность для нейронов - 5000 и batch_size = 10: 0.7593361139297485
Точность для нейронов - 5000 и batch_size = 100: 0.54356849193573
Точность для нейронов - 5000 и batch_size = 1000: 0.48547717928886414
Таким образом, можно заметить, что если поменять функцию активации в скрытом слое на linear, точность заметно упадёт. Это связано с тей, что обучать модели с линейной функцией в скрытых слоях неэффективно. Кроме того, чем меньше разбиение на batch_size, тем точность выше, модель учится лучше. Количество нейронов влияет, но не сильно.

Задание 20
Самостоятельно напишите нейронную сеть, которая может стать составной частью системы бота для игры в "Крестики-нолики". Используя подготовленную базу изображений, создайте и обучите нейронную сеть, распознающую две категории изображений: крестики и нолики. Добейтесь точности распознавания более 95% (accuracy)


[ ]
# Подключение класса для создания нейронной сети прямого распространения
from tensorflow.keras.models import Sequential
# Подключение класса для создания полносвязного слоя
from tensorflow.keras.layers import Dense
# Подключение оптимизатора
from tensorflow.keras.optimizers import Adam
# Подключение утилит для to_categorical
from tensorflow.keras import utils
# Подключение библиотеки для загрузки изображений
from tensorflow.keras.preprocessing import image
# Подключение библиотеки для работы с массивами
import numpy as np
# Подключение модуля для работы с файлами
import os
# Подключение библиотек для отрисовки изображений
import matplotlib.pyplot as plt
from PIL import Image
# Вывод изображения в ноутбуке, а не в консоли или файле
%matplotlib inline

[ ]
# Загрузка датасета из облака
import gdown
gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l3/hw_pro.zip', None, quiet=True)


[ ]
# Распаковываем архив hw_light.zip в папку hw_light
!unzip -q hw_pro.zip

[ ]
# Путь к директории с базой
base_dir = '/content/hw_pro'
# Создание пустого списка для загрузки изображений обучающей выборки
x_train = []
# Создание списка для меток классов
y_train = []
# Задание высоты и ширины загружаемых изображений
img_height = 20
img_width = 20
# Перебор папок в директории базы
for patch in os.listdir(base_dir):
    # Перебор файлов в папках
    for img in os.listdir(base_dir + '/' + patch):
        # Добавление в список изображений текущей картинки
        x_train.append(image.img_to_array(image.load_img(base_dir + '/' + patch + '/' + img,
                                                         target_size=(img_height, img_width),
                                                         color_mode='grayscale')))
        # Добавление в массив меток, соответствующих классам
        if patch == '0':
            y_train.append(0)
        else:
            y_train.append(1)
# Преобразование в numpy-массив загруженных изображений и меток классов
x_train = np.array(x_train)
y_train = np.array(y_train)
# Вывод размерностей
print('Размер массива x_train', x_train.shape)
print('Размер массива y_train', y_train.shape)
Размер массива x_train (102, 20, 20, 1)
Размер массива y_train (102,)

[ ]
from tensorflow.keras.layers import Flatten

#Нормализация входных данных.
y_train = utils.to_categorical(y_train, 2)                                      # Преобразуем в OHE.
x_train = x_train / 255.0

model13 = Sequential()                                                          # Создание последовательной модели.
model13.add(Flatten(input_shape=(20, 20, 1)))
model13.add(Dense(64, activation='relu'))                                       # Добавление полносвязного скрытого слоя на 64 нейрона …ов с функцией активации 'relu'.
model13.add(Dense(2, activation='softmax'))                                     # Добавление полносвязного выходного слоя на 2 нейрона с функцией активации 'softmax'.

model13.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy']) # Задание парметров обучения.
h = model13.fit(x_train, y_train, epochs = 15, batch_size = 15, validation_split = 0.2, verbose = 1) # Обучение модели.

print(f"Точность модели: {h.history['accuracy'][-1]}")
Epoch 1/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 3s 233ms/step - accuracy: 0.5247 - loss: 0.7483 - val_accuracy: 0.3333 - val_loss: 0.7824
Epoch 2/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 1s 7ms/step - accuracy: 0.6972 - loss: 0.6278 - val_accuracy: 0.0000e+00 - val_loss: 1.3093
Epoch 3/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.6558 - loss: 0.5587 - val_accuracy: 0.7619 - val_loss: 0.6105
Epoch 4/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.9325 - loss: 0.4930 - val_accuracy: 0.0476 - val_loss: 0.9333
Epoch 5/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7282 - loss: 0.4490 - val_accuracy: 0.5238 - val_loss: 0.6945
Epoch 6/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7870 - loss: 0.4788 - val_accuracy: 0.9048 - val_loss: 0.5405
Epoch 7/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.8150 - loss: 0.4092 - val_accuracy: 0.0000e+00 - val_loss: 1.0639
Epoch 8/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.8187 - loss: 0.3481 - val_accuracy: 1.0000 - val_loss: 0.3538
Epoch 9/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.9843 - loss: 0.3060 - val_accuracy: 0.3333 - val_loss: 0.7803
Epoch 10/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.9242 - loss: 0.2993 - val_accuracy: 0.9048 - val_loss: 0.4739
Epoch 11/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 1.0000 - loss: 0.2039 - val_accuracy: 0.9048 - val_loss: 0.4079
Epoch 12/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 1.0000 - loss: 0.1757 - val_accuracy: 0.9524 - val_loss: 0.3566
Epoch 13/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 1.0000 - loss: 0.1492 - val_accuracy: 0.9048 - val_loss: 0.3768
Epoch 14/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 1.0000 - loss: 0.1218 - val_accuracy: 0.9048 - val_loss: 0.3121
Epoch 15/15
6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 1.0000 - loss: 0.0988 - val_accuracy: 0.9048 - val_loss: 0.3488
Точность модели: 1.0
Задание 21
Распознайте рукописную цифру, написанную на листе от руки. Последовательность шагов следующая:

На бумаге рисуем произвольную цифру (желательно нарисовать цифру размером не более 5 * 5 мм и без наклона. В занятии нейронка обучалась на цифрах американских студентов. Эти цифры были написаны на тетрадных листах в клетку и имели схожий размер).
Фотографируем. Загружаем фото в Collaboratory.
С помощью функции image.load_img(path, target_size=(28, 28), color_mode = ‘grayscale’) загружаем картинку в переменную.
С помощью функции image.img_to_array(img) преобразуем изображение в numpy-массив.
Выполняем инверсию цветов, нормирование и решейп массива.
Выполняем распознавание собственной рукописной цифры.
Примечание: точность распознавания рукописных цифр может быть достаточно низкой, т.к. рукописные цифры после преобразований хоть и похожи на содержащиеся в базе, но могут отличаться по конфигурации, толщине линий и т.д.

Для выполнения этого задания нам понадобится код, который был написан на паре для распознавания цифр MNIST.


[ ]
from tensorflow.keras.datasets import mnist     # Библиотека с базой рукописных цифр
from tensorflow.keras.models import Sequential  # Подключение класса создания модели Sequential
from tensorflow.keras.layers import Dense       # Подключение класса Dense - полносвязный слой
from tensorflow.keras import utils              # Утилиты для подготовки данных
import numpy as np                              # Работа с массивами
import matplotlib.pyplot as plt                 # Отрисовка изображений

# Отрисовка изображений в ячейках ноутбука
%matplotlib inline

[ ]
# Загрузка из облака данных Mnist
(x_train_org, y_train_org), (x_test_org, y_test_org) = mnist.load_data()
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11490434/11490434 ━━━━━━━━━━━━━━━━━━━━ 2s 0us/step

[ ]
# Изменение формы входных картинок с 28х28 на 784
# первая ось остается без изменения, остальные складываются в вектор
x_train = x_train_org.reshape(x_train_org.shape[0], -1)
x_test = x_test_org.reshape(x_test_org.shape[0], -1)

[ ]
# Нормализация входных картинок
# Преобразование x_train в тип float32 (числа с плавающей точкой) и нормализация
x_train = x_train.astype('float32') / 255.

# Преобразование x_test в тип float32 (числа с плавающей точкой) и нормализация
x_test = x_test.astype('float32') / 255.

[ ]
# Задание константы количества распознаваемых классов

CLASS_COUNT = 10
# Преобразование ответов в формат one_hot_encoding
y_train = utils.to_categorical(y_train_org, CLASS_COUNT)
y_test = utils.to_categorical(y_test_org, CLASS_COUNT)

[ ]
# Создание последовательной модели
model = Sequential()
# Добавление полносвязного слоя на 800 нейронов с relu-активацией
model.add(Dense(800, input_dim=784, activation='relu'))
# Добавление полносвязного слоя на 400 нейронов с relu-активацией
model.add(Dense(400, activation='relu'))
# Добавление полносвязного слоя с количеством нейронов по числу классов с softmax-активацией
model.add(Dense(CLASS_COUNT, activation='softmax'))
# Компиляция модели
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Вывод структуры модели
print(model.summary())


[ ]
model.fit(x_train,        # обучающая выборка, входные данные
          y_train,        # обучающая выборка, выходные данные
          batch_size=128, # кол-во примеров, которое обрабатывает нейронка перед одним изменением весов
          epochs=15,      # количество эпох, когда нейронка обучается на всех примерах выборки
          verbose=1)      # 0 - не визуализировать ход обучения, 1 - визуализировать
Epoch 1/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 14s 25ms/step - accuracy: 0.8911 - loss: 0.3773
Epoch 2/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 21s 25ms/step - accuracy: 0.9753 - loss: 0.0825
Epoch 3/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 20s 24ms/step - accuracy: 0.9851 - loss: 0.0472
Epoch 4/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 10s 22ms/step - accuracy: 0.9907 - loss: 0.0297
Epoch 5/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 12s 25ms/step - accuracy: 0.9895 - loss: 0.0302
Epoch 6/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 20s 25ms/step - accuracy: 0.9935 - loss: 0.0197
Epoch 7/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 11s 24ms/step - accuracy: 0.9958 - loss: 0.0137
Epoch 8/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 10s 22ms/step - accuracy: 0.9959 - loss: 0.0127
Epoch 9/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 22s 25ms/step - accuracy: 0.9949 - loss: 0.0157
Epoch 10/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 12s 25ms/step - accuracy: 0.9963 - loss: 0.0102
Epoch 11/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 20s 23ms/step - accuracy: 0.9966 - loss: 0.0093
Epoch 12/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 11s 24ms/step - accuracy: 0.9970 - loss: 0.0097
Epoch 13/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 21s 25ms/step - accuracy: 0.9968 - loss: 0.0105
Epoch 14/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 19s 22ms/step - accuracy: 0.9966 - loss: 0.0108
Epoch 15/15
469/469 ━━━━━━━━━━━━━━━━━━━━ 11s 24ms/step - accuracy: 0.9964 - loss: 0.0108
<keras.src.callbacks.history.History at 0x7d9f396f0750>
Теперь перейдём к выполнению задания.

8.jpg


[ ]
img = '8.jpg'                                                                   # Наше фото.
img_p = image.load_img(img, target_size=(28, 28), color_mode='grayscale')       # Загружаем картинку в переменную.
x_test = image.img_to_array(img_p)                                              # Преобразуем в массив.

x_test = 255 - x_test                                                           # Инверсия цветов.
x_test = x_test.astype('float32') / 255.                                        # Нормализация.
x_test = x_test.reshape(1, 784)                                                 # Решейп массива.

res = model.predict(x_test)                                                     # Отправляем цифру в модель.

print(f"Распознана цифра: {np.argmax(res)}")                                    # выводим результат.

1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step
Распознана цифра: 8
#Таким образом, написанная цифра правильно распознана!
