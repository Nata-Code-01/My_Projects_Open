#Ссылка на коллаб: https://colab.research.google.com/drive/15oG9VmmXTQeNdsDkqXpLfcl92jn5ISbK?usp=sharing

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist                                    # библиотека базы выборок Mnist
from tensorflow import keras
from tensorflow.keras.layers import Dense, Flatten, Reshape, Input

(x_train, y_train), (x_test, y_test) = mnist.load_data()

# стандартизация входных данных
x_train = x_train / 255
x_test = x_test / 255

x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))

input_img = Input((28, 28, 1))
x = Flatten()(input_img)
x = Dense(128, activation='relu')(x)
x = Dense(64, activation='relu')(x)
encoded = Dense(49, activation='relu')(x)

d = Dense(64, activation='relu')(encoded)
d = Dense(128, activation='relu')(d)
d = Dense(28*28, activation='sigmoid')(d)
decoded = Reshape((28, 28, 1))(d)

autoencoder = keras.Model(input_img, decoded, name="autoencoder")
autoencoder.compile(optimizer='adam', loss='mean_squared_error')

autoencoder.fit(x_train, x_train, epochs=5, batch_size=100,
        shuffle=True)

n = 1

imgs = x_test[:n]
decoded_imgs = autoencoder.predict(x_test[:n], batch_size=10)

plt.figure(figsize=(2*n, 2*2))
for i in range(n):
  ax = plt.subplot(2, n, i+1)
  plt.imshow(imgs[i].squeeze(), cmap='gray')
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  ax2 = plt.subplot(2, n, i+n+1)
  plt.imshow(decoded_imgs[i].squeeze(), cmap='gray')
  ax2.get_xaxis().set_visible(False)
  ax2.get_yaxis().set_visible(False)

def plot_digits(*images):
    images = [x.squeeze() for x in images]
    n = min([x.shape[0] for x in images])

    plt.figure(figsize=(2*n, 2*len(images)))
    for j in range(n):
        for i in range(len(images)):
            ax = plt.subplot(len(images), n, i*n + j + 1)
            plt.imshow(images[i][j])
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)

    plt.show()

def plot_homotopy(frm, to, n=10, autoencoder=None):
    z = np.zeros(([n] + list(frm.shape)))
    for i, t in enumerate(np.linspace(0., 1., n)):
        z[i] = frm * (1-t) + to * t  # Гомотопия по прямой
    if autoencoder:
        plot_digits(autoencoder.predict(z, batch_size=n))
    else:
        plot_digits(z)

frm, to = x_test[y_test == 5][1:3]
plot_homotopy(frm, to)
plot_homotopy(frm, to, autoencoder=autoencoder)

frm, to = x_test[y_test == 8][1:3]
plot_homotopy(frm, to)
plot_homotopy(frm, to, autoencoder=autoencoder)

def Errors(m):
  input_img = Input((28, 28, 1))
  x = Flatten()(input_img)
  x = Dense(128, activation='relu')(x)
  x = Dense(64, activation='relu')(x)
  encoded = Dense(m, activation='relu')(x)

  d = Dense(64, activation='relu')(encoded)
  d = Dense(128, activation='relu')(d)
  d = Dense(28*28, activation='sigmoid')(d)
  decoded = Reshape((28, 28, 1))(d)

  autoencoder = keras.Model(input_img, decoded, name="autoencoder")
  autoencoder.compile(optimizer='adam', loss='mean_squared_error')

  history = autoencoder.fit(x_train, x_train, epochs=5)
  return(history.history['loss'][-1])

m_list = [49, 40, 30, 20, 10, 5, 2, 1]
result = []
for i in  range(len(m_list)):
  result.append(Errors(m_list[i]))
  print(Errors(m_list[i]))

m_list = [49, 40, 30, 20, 10, 5, 2]

plt.plot(m_list, result)
plt.show()

print(len(m_list), len(result))
